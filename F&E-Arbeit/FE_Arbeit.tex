% !TeX spellcheck = de_DE
\documentclass[
	oneside,  % falls doppelseitiger Druck gewünscht, "oneside" durch "twoside" ersetzen
	ngerman, 
	final, 
	11pt, 
	a4paper, 
	1.1headlines, 
	headinclude=false, 
	footinclude=false, 
	mpinclude=false, 
	pagesize, 
	onecolumn, 
	titlepage, 
	parskip=half, 
	headsepline, 
	chapterprefix=false, 
	version=first, 
	listof=totoc, 
	bibliography=totoc, 
	toc=graduated, 
	fleqn
]{scrbook}

%%%%%%%%%%% Verwendete Pakete %%%%%%%%%%%
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{babel}
\usepackage{hyperref}
\hypersetup{
	colorlinks=true,
	linkcolor=black,
	urlcolor=black,
	linktoc=all,
	citecolor=black
}
\usepackage{float}
\usepackage{graphicx}
\usepackage{textpos} 
\usepackage{tocloft}
\usepackage{lipsum}
\usepackage{color}
\usepackage[onehalfspacing]{setspace}
\usepackage{acronym}
\usepackage{multicol}
\usepackage{url}
\usepackage{longtable}

% Einbindung und Konfiguration von nomencl für Nomenklaturen
\usepackage{nomencl}

\renewcommand{\nomname}{Abkürzungsverzeichnis}

\providecommand{\printnomenclature}{\printglossary}
\providecommand{\makenomenclature}{\makeglossary}
\makenomenclature

% Einbindung und Konfiguration von listings für Quellcode-Listings
\usepackage{listings}

\renewcommand\lstlistlistingname{Quellcodeverzeichnis}
\renewcommand{\lstlistingname}{Quellcode}

\definecolor{default-lst-background}{RGB}{242,242,242}
\definecolor{default-lst-keyword}{RGB}{94,20,64}
\definecolor{default-lst-string}{RGB}{15,26,250}
\definecolor{default-lst-comment}{RGB}{31,97,46}

\definecolor{eclipse-java-background}{RGB}{235,235,235}
\definecolor{eclipse-java-keyword}{RGB}{127,0,85}
\definecolor{eclipse-java-string}{RGB}{42,0,255}
\definecolor{eclipse-java-comment}{RGB}{63,127,95}
\definecolor{eclipse-java-annotation}{RGB}{127,159,191}

\lstset{
	basicstyle={\footnotesize\fontfamily{pcr}\selectfont},
	backgroundcolor=\color{default-lst-background},
	keywordstyle=\color{default-lst-keyword}\bfseries,	
	stringstyle=\color{default-lst-string},
	commentstyle=\color{default-lst-comment}\itshape,
	frame=single,
	numbers=left,
	captionpos=b,
	showstringspaces=false,
	breaklines=true,
	tabsize=2
}

%% Listing-Style für Java, der das Syntax Highlighting wie in Eclipse vornimmt
\lstdefinestyle{eclipse-java}{	
	backgroundcolor=\color{eclipse-java-background},
	keywordstyle={\color{eclipse-java-keyword}\bfseries},
	stringstyle={\color{eclipse-java-string}},
	commentstyle={\color{eclipse-java-comment}},		
	moredelim={[il][\textcolor{eclipse-java-annotation}]{\%}},
	moredelim={[is][\textcolor{eclipse-java-annotation}]{\%\%}{\%\%}}
}

%%%%%%%%%%% Weitere Konfigurationen %%%%%%%%%%%
% Schachtelungstiefe
\setcounter{secnumdepth}{3}
\setcounter{tocdepth}{3}

% Schriftart
\makeatletter
\setkomafont{disposition}{\normalcolor\bfseries}
\makeatother

% Balkenfarbe Titelseite
\definecolor{titlepage-rule-color}{RGB}{194,191,194}

%%%%%%%%%%% Angaben zur Arbeit und Autorinnenschaft %%%%%%%%%%%
% Angaben zu Ihrer Arbeit. Bitte ersetzen Sie die Werte der Makros durch die passenden.
%% Art der Arbeit. Gültige Werte: "Projektarbeit", "Bachelorthesis", "Masterseminar", "F\&E-Arbeit", "Masterthesis".
\newcommand*{\fhdopaperkind}{F\&E-Arbeit}
%% Titel
\newcommand*{\fhdopapertitle}{Gamification zur nachhaltigen Steigerung der Code-Qualität in coderadar}
%% optionaler Untertitel, der etwas länger als der Titel sein kann
\newcommand*{\fhdopapersubtitle}{Forschungs- und Entwicklungs-Arbeit}
%% Datum der Abgabe im Format DD.MM.YYYY
\newcommand*{\fhdopaperdate}{Datum der Abgabe}
%% erste Betreuerin
\newcommand*{\fhdopaperfirstsupervisor}{Prof. Dr. Andreas Harrer} 
%% zweite Betreuerin inklusive Abschluss, also z. B. "B.Sc." oder "M.Sc."
\newcommand*{\fhdopapersecondsupervisor}{Vorname Nachname, Abschluss}

% Angaben zu Ihnen als Autorin. Bitte ersetzen Sie die Werte der Makros durch die passenden.
%% vollständiger Name
\newcommand*{\fhdopaperauthor}{Johannes Teklote}
%% Geburtstag
\newcommand*{\fhdopaperbirthday}{02.01.1996}
%% Matrikelnummer
\newcommand*{\fhdopaperstudentnumber}{7091992}
%% Studiengang
\newcommand*{\fhdopapermajor}{Praktische Informatik}
%% Der durch Ihren Studiengang angestrebte Abschluss. Gültige Werte: "Bachelor", "Master".
\newcommand*{\fhdopaperdegree}{Master} 

\begin{document}
%%%%%%%%%%% Titelseite. Bitte unverändert lassen. %%%%%%%%%%%
\begin{titlepage}
	\begin{textblock}{6.5}(-1,-3)
		\begin{color}{titlepage-rule-color}
			\rule{6.8cm}{33cm}    
		\end{color}
	\end{textblock}

	\begin{textblock}{6.5}(-0.8,1)\textsf{%
		\Large 
		\fhdopaperkind
	}\end{textblock}

	\begin{textblock}{7}(4.5,2)\textsf{%
		\noindent 
		\huge 
		\textbf{\fhdopapertitle}\\[0.3cm] 
		\Large \fhdopapersubtitle\\[0.05cm]
	}\end{textblock}

	\begin{textblock}{6}(4.5,6.5)\textsf{%
		\noindent
		An der Fachhochschule Dortmund\\
		im Fachbereich Informatik\\
		Studiengang \fhdopapermajor{}\\
		erstellte \fhdopaperkind{}\\
		zur Erlangung des akademischen Grades\\
		\fhdopaperdegree{} of Science
	}\end{textblock}

	\begin{textblock}{6.5}(-0.4,10.0)\textsf{%
		\noindent
		von\\
		\fhdopaperauthor{}\\
		geb. am \fhdopaperbirthday\\
		Matr.-Nr. \fhdopaperstudentnumber\\[0.7cm]
		Betreuer:\\
		\hspace*{6mm} \fhdopaperfirstsupervisor{}\\
		\noindent\hspace*{6mm} \fhdopapersecondsupervisor{}\\[0.5cm]
		Dortmund, \fhdopaperdate
	}\end{textblock}
\end{titlepage}
	
\newpage{}

%%%%%%%%%%% Inhalt der Arbeit. Ab hier sind wieder Änderungen erlaubt. %%%%%%%%%%%

% Kurzfassung
\section*{\thispagestyle{empty}Kurzfassung}
\lipsum[1-2]

\newpage{}

% Abstract (= Kurzfassung auf Englisch)		
\section*{\thispagestyle{empty}Abstract}		
\lipsum[1-2]

\newpage{}

% Inhaltsverzeichnis. Bitte unverändert lassen.
%% Römische Nummerierung
\setcounter{page}{1}
\pagenumbering{roman}
\tableofcontents
		
\newpage{}
		
%% Nach Inhaltsverzeichnis wieder arabische Nummerierung mit Neubeginn Nummerierung
\setcounter{page}{1} 
\pagenumbering{arabic}


%___________________________________________________________________________________________________

% Weiter mit dem Inhalt der Arbeit. Ab hier sind wieder Änderungen erlaubt.
\chapter{Einleitung}
\label{Einleitung}

		
\section{Motivation}
\label{Motivation}
Laut \cite{Balzert2009} entfallen 80\% des Aufwands in der Softwareentwicklung auf deren Wartung, wobei 40\% davon benötigt werden, um die zu wartende Software zu verstehen.
Ein erheblicher Teil der Kosten für die Softwareentwicklung entfällt damit auf das Verstehen der Software.
Wenn insgesamt die Entwicklungskosten reduziert werden sollen, stellt dieser Umstand einen wesentlichen Hebel dar.
Denn der Wartungsaufwand im Übrigen ist vielfach kaum zu verringern, weil sich die Anforderungen an die Software im Laufe der Zeit ändern, weil auftretende Probleme behoben werden müssen oder weil Abhängigkeiten auf andere Software, Frameworks oder Komponenten angepasst werden müssen.
Bereits durch das Erfüllen gewisser Qualitätsstandards lässt sich jedoch der für das Verstehen des Codes notwendige Aufwand reduzieren.

Qualitativ hochwertige Software zeichnet sich nach der \acf{ISO} 25010 dadurch aus, dass sie stabil ist und gut gewartet, analysiert, erlernt und verändert werden kann (vgl. \cite{ISO-25010}).
Software, die diese Anforderungen erfüllt, beinhaltet Code, der bestimmten Richtlinien entspricht.
Zu diesen Richtlinien gehört beispielsweise, dass Code auf einer Ebene einheitlich eingerückt wird, dass öffnende geschweifte Klammern in der gleichen Zeile stehen wie der Code, der die Klammer erfordert, dass Variablennamen sprechend sind und nicht nur aus einem Buchstaben bestehen oder dass Parameter auf ihre Gültigkeit überprüft werden, bevor mit ihnen gearbeitet wird.

Die Einhaltung solcher Regeln scheint auf den ersten Blick nur von geringer Bedeutung zu sein, allerdings lenken beispielsweise Unstimmigkeiten in der Formatierung beim Lesen des Codes ab und sie erschweren es, sich auf den eigentlichen Code zu konzentrieren.
In \cite{PJ2015} und \cite{SP2011} werden diese Formatverstöße als Hintergrundrauschen beschrieben, das vom eigentlichen Code ablenkt. 

Code, der nach den oben beschriebenen Regeln geschrieben wurde, ist laut \cite{PJ2015} leichter verständlich und dadurch auch leichter erlernbar und veränderbar.
Um die Mitglieder des Entwicklungsteams dazu zu bringen, sich an die vereinbarten Regeln zu halten, gibt es zwei Möglichkeiten.
Zum einen kann im Reviewprozess des Projekts ein automatischer Test eingebaut werden, der dafür sorgt, dass grundsätzlich funktionierender Code dann nicht angenommen wird, wenn er gegen festgelegte Regeln verstößt, wenn er also beispielsweise Stylingrichtlinien nicht einhält oder es potentiell unsichere Variablenzugriffe gibt.
Zum anderen können die Teammitglieder durch Belohnungen dazu motiviert werden, von sich aus die festgelegten Regeln einzuhalten und dies auch selbst zu überprüfen. 
Es stellt sich nun die Frage, ob eine solche Motivation durch Gamification erreicht werden kann.
Bei Gamification werden Methoden genutzt, die aus Spielen bekannt sind.
Dazu gehören beispielsweise Levels, Badges oder Leader Boards, die das Team oder ein einzelnes Teammitglied erreichen kann. 

Die oben beschriebene Ablehnung von eingereichtem Code auf Grund von Verstößen gegen Richtlinien führt dazu, dass die Teammitglieder die vereinbarten Programmierrichtlinien mit der Zeit von sich aus einhalten, ohne immer darauf hingewiesen werden zu müssen.
Es ergibt sich also ein Lerneffekt, der bewirkt, dass die Teilnehmer in Zukunft qualitativ hochwertigen Code einreichen.
Im Rahmen dieser Arbeit soll untersucht werden, ob beziehungsweise in wie weit auszuwählende Gamification-Elemente ebenfalls die Motivation erhöhen, qualitativ hochwertigeren Code einzureichen.
Neben qualitativ hochwertigem Code könnte so durch einen gewissen \glqq Spaßfaktor\grqq{} auch eine höhere Zufriedenheit der Teammitglieder erreicht werden.
		
\section{Zielsetzung}
\label{Zielsetzung}
Ziel dieser Arbeit ist die Erweiterung der Codeanalyseplattform coderadar \footnote{\url{https://github.com/adessoAG/coderadar}} um Gamification-Elemente zur Steigerung der Code-Qualität.
Dazu werden zunächst Analysemechanismen zur Bewertung des Codes ausgewählt.
Anschließend werden Gamification-Elemente ausgewählt und in coderadar implementiert.
Mit einer Balancierungsmatrix wird dann die Bewertung des Codes gewichtet und in eine absolute Punktzahl umgerechnet.
Auf dieser Punktzahl basieren dann Levels, Leader Boards und ähnliches.
Ein Feldversuch zur Feststellung, in wie weit die implementierten Maßnahmen die Softwarequalität nachhaltig verbessern, soll im Rahmen der F\&E-Arbeit nicht stattfinden.
Dies geschieht erst im Rahmen der Masterthesis.
		
\section{Vorgehensweise}
\label{Vorgehensweise}
Zunächst werden in Kapitel \ref{Technische_Grundlagen} die Grundlagen für diese Arbeit vorgestellt.
Dazu gehört zunächst die Definition von Gamification im Rahmen dieser Arbeit in Abschnitt \ref{Gamification}.
Im Anschluss daran wird in Abschnitt \ref{Kriterien_guter_Code} beschrieben, was qualitativ gute Software genau ausmacht.
Dazu wird ausgeführt, welche Qualitätsmetriken es für Software gibt und wie ihre Werte zu verstehen sind.

In Kapitel \ref{Projektkontext} wird dann die Problemstellung (vgl. Abschnitt \ref{Motivation}) analysiert.
Dazu wird zunächst in Abschnitt \ref{Problembeschreibung} das grundlegende Problem beschrieben.
Dieses Problem wird in Abschnitt \ref{Kontext} in den bestehenden Kontext des Codeanalysewerkzeugs coderadar eingeordnet.
Auf Basis dieser Ergebnisse werden dann Anforderungen an eine Software herausgearbeitet, die im Rahmen dieser Arbeit implementiert werden und die beschriebenen Probleme lösen soll.
Abschließend erfolgt die wissenschaftliche Einordnung der Arbeit in Abschnitt \ref{Wissenschaftliche_Einordnung}.

Der Entwurf eines Lösungsansatzes für das oben beschriebene Problem erfolgt in Kapitel \ref{Entwurf}.
Dazu wird zunächst in Abschnitt \ref{Codeanalyse} vorgestellt, wie Code in coderadar analysiert werden kann.
Ein besonderes Augenmerk wird dabei auf mögliche Herausforderungen während der Analyse gelegt.
Anschließend werden in Abschnitt \ref{Architektur} auf Basis der bestehenden coderadar-Architektur sinnvolle Möglichkeiten zur Ergänzung der Analyse und der Einarbeitung von Gamification-Elementen erarbeitet.
Danach wird in Abschnitt \ref{Metrikmatrix} eine Matrix erstellt, in der festgelegt wird, in welchem Umfang welche Metrik in die Berechnung eines Scores für die Güte der Software einfließen soll.
Anschließend wird in Abschnitt \ref{Gamification_Elemente} erarbeitet, wie welche Gamification-Elemente im User-Interface verwendet werden können, um den berechneten Score darzustellen und Motivation zur Verbesserung dieses Scores zu liefern.

Kapitel \ref{Umsetzung} beschäftigt sich dann mit der programmatischen Umsetzung des beschriebenen Lösungsansatzes. 

Abschließend werden in Kapitel \ref{Abschluss} die Ergebnisse dieser Arbeit zusammengefasst.
Dazu wird zunächst in Abschnitt \ref{Verifizierung_Anforderungen} die Umsetzung der gestellten Anforderungen überprüft.
Anschließend wird in Abschnitt \ref{Fazit} ein Fazit aus der Implementierung gezogen.
Zum Schluss wird ein Ausblick auf die weitere Arbeit mit den implementierten Gamification-Elementen in coderadar gegeben.

\chapter{Grundlagen}
\label{Technische_Grundlagen}
Dieses Kapitel geht auf die technischen Grundlagen der Arbeit ein.
Dazu gehört zunächst die Erläuterung von Gamification und Gamification-Elementen in Abschnitt \ref{Gamification}.
Danach werden in Abschnitt \ref{Kriterien_guter_Code} grundlegende Kriterien für qualitativ hochwertige Software vorgestellt.
Dabei als Basis dienen dabei die Kriterien für Softwarequalität aus der \acs{ISO} 25010 (vgl. \cite{ISO-25010}).
Aus diesen Kriterien werden die ausgewählt, die durch coderadar gemessen werden können. 

\section{Gamification}
\label{Gamification}
In diesem Abschnitt wird der Begriff Gamification erläutert.
Dazu erfolgt zunächst in Abschnitt \ref{Definition} eine Definition des Begriffs sowie eine Einordnung der Gamification in die Formen des Spielens nach \cite{DD2011}.
Anschließend wird in Abschnitt \ref{Spielermotivation} beschrieben, wie Motivation erreicht beziehungsweise gesteigert werden kann.
In Abschnitt \ref{Elemente} werden dann einige Gamification-Elemente vorgestellt und es wird ausgearbeitet, welche dieser Elemente im Rahmen dieser Arbeit verwendet werden sollen..

\subsection{Definition und Einordnung}
\label{Definition}
Nach \cite{SH2014} ist Gamification die Nutzung der Motivationskraft von Spielen in anderen Bereichen, die nicht der Unterhaltung dienen.
Um dies zu bewerkstelligen, werden Elemente aus dem Gamedesign verwendet.
Zu diesen Elementen gehören beispielsweise Punktestände, Level, Bestenlisten, Fortschrittsanzeigen oder Aufgaben beziehungsweise Herausforderungen (vgl. Abschnitt \ref{Elemente}).
Durch die Ausrichtung dieser Elemente an einem übergeordneten Ziel kann die Motivation der Spieler auf das Erfüllen dieses Ziels gerichtet werden (vgl. Abschnitt \ref{Spielermotivation}).

\begin{figure}[htb]
	\begin{center}
		\includegraphics[scale=0.6]{images/gamification_einordnung}
		\caption{Die verschiedenen Arten des Spielens nach \cite{DD2011}.}
		\label{gamification_einordnung}
	\end{center}
\end{figure}

Der Begriff Gamification ist von dem Wort \glqq Gaming\grqq{} abgeleitet.
Gaming bezieht sich dabei auf ein seriöses Spielen.
Dies steht dabei dem \glqq Playing\grqq{} gegenüber (vgl. Abbildung \ref{gamification_einordnung}).
Playing beschreibt nach \cite{Wa2003} ein Spielen in einer offenen Welt, die oft nur durch die Kreativität der Spieler beschränkt ist.
Der Aufbau der Spielwelt, beispielsweise mit Spielzeugen wie Lego, ist dabei ein zentraler Aspekt.
Gaming unterscheidet sich nach \cite{DD2011} von Playing dadurch, dass das Gaming einem Regelwerk unterliegt, welches die Teilnehmer beim Erreichen eines gesetzten Ziels einschränkt, was somit eine Herausforderung darstellt.
Am Beispiel Schach verdeutlicht, liegt das Ziel darin, den gegnerischen König zu schlagen, ohne dass der eigene König geschlagen wird.
Einschränkend gilt hierbei, dass die Spieler immer abwechselnd ziehen und die Figuren in ihrer Beweglichkeit eingeschränkt sind.
Zusätzlich gibt es teilweise noch eine zeitliche Einschränkung, sodass für alle Züge zusammen in Summe nur eine gewisse Zeit zur Verfügung steht.

Gamification ist die Übertragung von Elementen aus dem Gaming in Bereiche, die nicht mit dem Spielen oder der Unterhaltung generell verwandt sind.
Gamification beim Joggen wäre beispielsweise, dass als Ziel eine vorher festgelegte Distanz von 20 km in einer Woche zurückgelegt werden soll.
Die Erreichbarkeit dieses Ziels ist dadurch eingeschränkt, dass nur eine Woche für das Zurücklegen der 20 km zur Verfügung steht und der Spieler gegebenenfalls diese Strecke nicht in einem Mal zurücklegen kann, sodass er beispielsweise zwei Läufe mit jeweils 10 km aufsummieren muss.

Im Rahmen dieser Arbeit besteht dieses Ziel darin, möglichst qualitativ hochwertigen Code zu produzieren.
Entsprechend würde ein Spieler, der qualitativ hochwertigeren Code einreicht, mehr Punkte bekommen und somit auch schneller im Level aufsteigen.
Die Spieler sind dabei unter anderem durch die Projektlaufzeit und das zur Verfügung stehende Budget für einzelne Teilaufgaben eingeschränkt.

\subsection{Spielermotivation}
\label{Spielermotivation}
Motivation ist laut \cite{SH2014} ein psychologischer Prozess, der ein zielgerichtetes Handeln initiieren oder verstärken kann.
Für die Effektivität von Gamification ist entscheidend, dass beim Spieler Motivation generiert wird, das gesetzte Ziel zu erreichen.
Dazu kann das Fördern von Motivation aus verschiedenen Perspektiven betrachtet werden, entsprechend gibt es verschiedene Arten, die Motivation zu fördern.

\paragraph{Bedürfnisse des Spielers}
Spieler haben laut \cite{SH2014} verschiedene Bedürfnisse, die sie erfüllen wollen.
Diese sind dabei abhängig von der Ausprägung unterschiedlicher Charakterzüge eines Spielers.
Hier werden das Bedürfnis nach Erfolg, Einfluss und Statussymbolen und das Bedürfnis nach Zusammengehörigkeit betrachtet.
Dadurch, dass einem Spieler ein Erfolg oder eine Gruppenzugehörigkeit in Aussicht gestellt wird, hat der Spieler die Möglichkeit, dieses Bedürfnis zu befriedigen, und er wird versuchen, die notwendigen Anforderungen zu erfüllen.

\paragraph{Positive und negative Eindrücke}
Aus der Betrachtung der verhaltensorientierten Perspektive geht laut \cite{SH2014} hervor, dass positive und negative Eindrücke oder Erfahrungen zukünftiges Verhalten beeinflussen.
Entsprechend kann durch positives und negatives Feedback oder Belohnungen und Bestrafungen zukünftiges Verhalten gesteuert werden.

\paragraph{Erfüllung von Erwartungen}
Laut \cite{SH2014} ist Motivation aus der kognitiven Perspektive abhängig von den an den Spieler gestellten Erwartungen.
Diese Erwartungen können allgemeingültig sein und beispielsweise durch das Alter oder die erwarteten Fähigkeiten bestimmt sein, oder es sind die der Spieler an sich selbst hat.
Motivation wird dabei durch die Erfüllung beziehungsweise das Bedürfnis nach Erfüllung dieser Erwartungen generiert.

\paragraph{Selbstverwirklichung}
Selbstverwirklichung ergibt sich nach \cite{SH2014} aus den Bedürfnissen nach Autonomie, Kompetenz und sozialer Verbundenheit.
Die Erfüllung dieser Bedürfnisse fördert laut \cite{SH2014} die intrinsische Motivation des Spielers.

\paragraph{Nutzerinteressen und Flow}
Die Interessensperspektive berücksichtigt laut \cite{SH2014} individuelle Vorlieben und inhaltliche Aspekte.
Motivation ergibt sich demnach aus der Beziehung des Spielers zu der Aufgabe oder dem Kontext.
Idealerweise kann dies laut \cite{SH2014} zu einem vollständigen Eintauchen in die Aufgabe führen, dem sogenannten \glqq Flow\grqq{}.
\cite{Zi2011} erklärt Flow als einen Zustand, in dem der Anspruch einer Aufgabe den Fähigkeiten des Spielers exakt entspricht.
Übersteigen die Fähigkeiten den Anspruch der Aufgabe, langweilt sich der Spieler und er ist weniger motiviert.
Übersteigt der Anspruch hingegen die Fähigkeiten, gerät der Spieler unter Leistungsdruck und er sorgt sich um die Erfüllung der Aufgabe, was laut \cite{As2000} bis hin zu Angstzuständen führen kann.
Auch dadurch sinkt die Motivation des Spielers.
Das Erreichen der Flow-Zone, in der die Fähigkeiten des Spielers den Ansprüchen der Aufgabe entsprechen, erfordert demnach eine genaue Abstimmung dieser beiden Aspekte.

\paragraph{Emotionales Empfinden}
Auch über die emotionale Ebene lässt sich laut \cite{SH2014} Motivation generieren.
\cite{As2000} führt an, dass unterschiedlich formulierte Aufgabenstellungen Motivation fördern oder einschränken können.
Demnach lässt sich Motivation durch die Verminderung negativer Emotionen wie Angst, Ärger oder Neid und die Verstärkung positiver Emotionen wie Sympathie oder Freude fördern.

\subsection{Gamification-Elemente}
\label{Elemente}
Um in einem Spiel die Motivation des Spielers zu steigern, ist es wichtig, dass er ein Feedback zu seinem aktuellen Fortschritt bekommt.
Am Beispiel Schach geschieht dies durch die Stellung der Figuren und somit die Feldhoheit.
Am Beispiel der Gamification beim Joggen könnte dies ein Abbild der Gesamtdistanz und ein entsprechender Positionsmarker mit der aktuell zurückgelegten Distanz sein.
Wie oben beschrieben, werden für diese Darstellung Elemente aus dem Gamedesign verwendet.
Im Folgenden werden einige Elemente beispielhaft vorgestellt und ihr Nutzen erläutert.

\paragraph{Punkte}
Punkte dienen laut \cite{SH2014} zur Darstellung der aktuellen Situation.
Sie können auch zur Veranschaulichung von Belohnungen verwendet werden und geben ein direktes Feedback.
Dieses Feedback kann durch das Erhalten von Punkten positiv beziehungsweise durch das Verlieren von Punkten negativ sein.

\paragraph{Badges}
Badges oder Auszeichnungen sind Statussymbole innerhalb der Gamification.
Sie erfüllen das Bedürfnis des Spielers nach Erfolg und Anerkennung (vgl. \cite{SH2014}).
Darüber hinaus fungieren sie laut \cite{SH2014} als eine Form der Gruppenidentifikation, da sie gemeinsame Erfahrungen kommunizieren.
Für Spieler, die ein bestimmtes Badge noch nicht erreicht haben, können sie außerdem als Ziel fungieren, dessen Belohnung dann das Erhalten dieses Badges ist.

\paragraph{Fortschrittsbalken}
Fortschrittsbalken veranschaulichen einen Fortschritt hinsichtlich eines Ziels.
Sie gelten dabei individuell für einen Spieler und zeigen an, wie weit der Spieler von der Erfüllung des Ziels entfernt ist.

\paragraph{Leistungsdiagramme}
Leistungsdiagramme setzten einen individuellen Score in Relation zu anderen Scores.
Diese anderen Scores können von anderen Spielern oder anderen Zeitpunkten stammen.
Stammen sie von anderen Spielern, zeigt das Diagramm, wie der Spieler sich im Vergleich zu anderen Spielern im Bezug auf ein Ziel hin entwickelt.
Betrachtet das Diagramm hingegen unterschiedliche Zeitpunkte desselben Spielers, liegt der Fokus auf der Verbesserung der Fähigkeiten des Spielers und fördert das Verbessern dieser (vgl. \cite{SH2014}). 

\paragraph{Quests}
Quests sind laut \cite{SH2014} kleine Aufgaben oder Herausforderungen mit einem klar definierten Ziel.
Der Fortschritt auf dieses Ziel hin muss dabei transparent sein, sodass es für den Spieler ersichtlich ist, welche Konsequenzen seine Aktionen im Bezug auf das Erreichen des Ziels haben.
Das Erreichen dieses Ziels ist dabei immer mit einer Belohnung verknüpft.

\paragraph{Avatare und Profile}
Avatare beziehungsweise Profile und deren Entwicklung repräsentieren den Spieler.
Spieler können eine Verbundenheit zu ihren Avataren aufbauen, sodass ein Fortschritt des Avatars einen persönlichen Fortschritt bedeutet (vgl. \cite{SH2014}).

\paragraph{Leaderboards}
Leaderboards oder Bestenlisten stellen die Einordnung eines Spielers im Vergleich zu den besten Spielern dar.
Spieler, die nicht an der Spitze stehen, könnten allerdings demotiviert werden, da ihre schlechteren Leistungen veröffentlicht werden (vgl. \cite{SH2014}).
Dies führt dazu, dass der Einsatz von Leaderboards kritisch zu sehen ist.
Durch die Verwendung von Team-Leaderboards können diese negativen Effekte allerdings etwas reduziert werden, da sie den Fokus auf die Teamleistung legen.
Zum einen wird dadurch kein einzelner Spieler \glqq bloßgestellt\grqq{} und zum anderen hat das Team ein gemeinsames Ziel, auf das es hinarbeiten kann, wodurch sich laut \cite{SH2014} die Verbundenheit im Team erhöht. 

\section{Kriterien für qualitativ hochwertigen Code}
\label{Kriterien_guter_Code}
Ein zentraler Aspekt dieser Arbeit ist die Messung von Codequalität.
Dazu muss zunächst definiert werden, was im Rahmen dieser Arbeit unter qualitativ hochwertigem Code verstanden wird.
Dies geschieht auf Basis der Kriterien für Softwarequalität aus \acs{ISO} 25010 (vgl. \cite{ISO-25010})
Im Rahmen der Codeanalyse mit coderadar sind allerdings nicht alle dieser Kriterien zur Bewertung des Codes geeignet.
coderadar analysiert Java\footnote{\url{https://java.com/de/}}-Code anhand der in der Versionsverwaltung vorliegenden \textit{.java}-Dateien.
Zusätzlich kann aus dem vorliegenden Quellcode der Binärcode, die \textit{.class}-Dateien, generiert werden.
Eine Analyse des Programms im laufenden Betrieb ist hier nicht möglich, da dafür zum einen viel Rechenleistung benötigt werden könnte und zum anderen Ausführungsumgebungen wie Docker gegebenenfalls nicht zur Verfügung stehen.
Darüber hinaus ist es auf Grund des Halteproblems nicht möglich, vorauszusagen, wie lange die Ausführung des Programms dauert, sodass eine zeiteffiziente Analyse eventuell nicht möglich ist (vgl. \cite{Davis2013}).
Entsprechend findet in diesem Abschnitt eine Eignungsprüfung der jeweiligen Kriterien statt.
In Abschnitt \ref{Auswahl_Kriterien} wird dann die Liste an Kriterien, die im Rahmen dieser Arbeit verwendet werden, zusammen mit den Metriken, die zur Messung verwendet werden, vorgestellt.

\subsection{Funktionale Vollständigkeit}
Die funktionale Vollständigkeit beispielsweise ist immer von den Anforderungen innerhalb des Projekts abhängig.
Ohne Kenntnis dieser Anforderungen lassen sich auch keine Aussagen über den Erfüllungsgrad der Anforderungen und somit über die funktionale Vollständigkeit treffen.
Darüber hinaus ist die Überprüfung von Semantik innerhalb der Software nur sehr schwer möglich, da dafür Intelligenz notwendig ist, die ein Computerprogramm nicht liefern kann.
Des Weiteren ist es nicht möglich automatisiert zu prüfen, ob ein Programm fehlerfrei ist, es lässt sich lediglich validieren, dass ein Programm für eine gegebene Liste an Eingaben die gewünschten Ausgaben erzeugt (vgl. \cite{Di1972}).
Entsprechend wird in dieser Arbeit die funktionale Vollständigkeit als Kriterium für die Codequalität nicht berücksichtigt.

\subsection{Nutzbarkeit}
Die Aspekte Nutzbarkeit, Erlernbarkeit und Barrierefreiheit beziehen sich auf die Benutzeroberfläche des Programms.
Da eine in Java geschriebene Benutzeroberfläche nur in einigen Anwendungen vorhanden ist, können hier nur schwer gerechte Bewertungen vorgenommen werden, da viele Projekte nicht in diesem Aspekt bewertet werden können.
Die Bewertung von Projekten, die für die Benutzeroberfläche nicht Java verwenden oder keine Benutzeroberfläche haben, wäre verzerrt, da ein Ausgleich für die in diesem Kriterium vergebenen Punkte geschaffen werden müsste.
Daher wird im Rahmen dieser Arbeit der Aspekt der Nutzbarkeit vernachlässigt.

\subsection{Performanz}
Auch ist es schwer, die Performanz und den Ressourcenverbrauch einer Funktion zu ermitteln, ohne den semantischen Hintergrund zu kennen oder die Funktion auszuführen.
Der Ressourcenverbrauch in Form der Netzwerklast oder des Speicherverbrauchs lässt sich nur schwer voraussagen und müsste im laufenden Betrieb gemessen werden.
Daher wird dieser Aspekt im Rahmen dieser Arbeit vernachlässigt.

\subsection{Kompatibilität}
Auf die Kompatibilität zu anderer Software können in hier nur schwer Rückschlüsse gezogen werden.
Dafür würden Kenntnisse über diese andere Software benötigt.
Anschließend müssten die Aufrufe und Implementierungen von Schnittstellen untersucht werden.
Java bietet allerdings verschiedene Möglichkeiten, um Schnittstellen zu anderer Software aufzurufen.
Dies kann über \acf{REST}- beziehungsweise \acf{SOAP}-Anfragen, für die es verschiedene Implementierungen gibt, als auch über das Importieren dieser anderen Software als Abhängigkeit geschehen.
Die Entwicklung der Muster zur Erkennung dieser Aufrufe und Implementierungen geht dabei über den zeitlichen Rahmen dieser Arbeit hinaus.
Auch zur Koexistenz neben anderen Systemen lassen sich nur schwer Aussagen tätigen, da das Programm hierzu im laufenden Betrieb untersucht werden muss.

\subsection{Zuverlässigkeit}
Die Zuverlässigkeit von Software lässt sich durch Codeanalysen gut bewerten.
Zum einen kann unter dem Aspekt des Reifegrads des Programms die Testabdeckung untersucht werden.
Durch eine hohe Testabdeckung kann erreicht werden, dass verifiziert wird, dass die Methoden das machen, was sie sollen.
Dabei muss aber auch darauf geachtet werden, dass die Tests dazu geeignet sind, den Code zu testen.
Es ist auch möglich, eine hohe Testabdeckung zu erreichen, ohne dass die Funktionsweise tatsächlich geprüft wurde.
Die Testabdeckung besitzt dementsprechend nur eingeschränkte Aussagekraft zur Zuverlässigkeit der Software.

Ein weiterer Aspekt der Zuverlässigkeit ist die Fehlertoleranz.
Damit eine Anwendung Tolerant gegenüber Fehlerfällen ist, müssen diese Fehlerfälle erkannt und durch eine alternative Abarbeitungsvariante behandelt werden können.
Fehlerfälle wie beispielsweise invalide Nutzereingaben können innerhalb der statischen Codeanalyse durch entsprechend gewählte Testfälle überprüft werden.
Dies setzt allerdings voraus, dass solche Tests existieren.
Es müsste also gezeigt werden, dass das Programm fehlerfrei ist, was nach \cite{Di1972} nicht möglich ist.
Auch die Toleranz gegenüber Fehlern außerhalb des Programms, beispielsweise Netzwerkfehler, Stromausfälle oder Speicherfehler, sind ein Aspekt der Fehlertoleranz.
Innerhalb einiger Frameworks gibt es hierfür teilweise Maßnahmen, Spring\footnote{\url{https://spring.io/}} bietet hier beispielsweise den Cirquit Breaker\footnote{\url{https://spring.io/projects/spring-cloud-circuitbreaker}}.
Es könnte in den Fällen, in denen solche Frameworks verwendet wurden, eine Validierung stattfinden, dieser Sonderfall ist aber zu speziell als dass er in dieser Arbeit berücksichtigt werden soll.
Entsprechend wird der Aspekt der Fehlertoleranz im Rahmen dieser Arbeit für die Zuverlässigkeit nicht berücksichtigt.

Die Wiederherstellbarkeit ist ein weiterer Bereich innerhalb der Zuverlässigkeit.
Sie wird allerdings hauptsächlich vom System auf dem das Programm ausgeführt wird beeinflusst.
Maßnahmen an dieser Stelle sind beispielsweise eine geeignete Backup-Strategie oder die Replikation einzelner der Anwendung oder einzelner Teile dieser.
Entsprechend wird die Wiederherstellbarkeit für die Messung der Codequalität hier auch nicht berücksichtigt.

\subsection{Sicherheit}
Die Sicherheit eines Programms ist in \cite{ISO-25010} definiert als Grad zu dem das Programm Daten vor unbefugten Zugriffen schützt.
Das Programm nun dahingehend zu analysieren, dass alle Funktionen mit den entsprechenden Zugriffsbeschränkungen versehen worden sind, ist wieder eine semantische Überprüfung und somit nur schwer umzusetzen.
Dies gilt auch für die Validierung, ob vor jedem Zugriff eine Authentifizierung korrekt erfolgt ist.

Die Nachverfolgbarkeit von Aktionen innerhalb des Programms ist ein weiterer Aspekt der Sicherheit.
Hierzu gehört zum einen, das belegt werden kann, dass eine Aktion oder ein Ereignis stattgefunden hat und zum anderen wer diese Aktion ausgeführt hat.
Im Programm können hierzu beispielsweise Log-Ausgaben verwendet werden.
Um mit Hilfe von Mustererkennung im Code zu validieren, dass entsprechende Ausgaben getätigt werden, müssten zunächst Muster zur Erkennung von Befehlen zum Ausführen von Log-Ausgaben entwickelt werden, was den zeitlichen Rahmen dieser Arbeit überschreitet.
Im laufenden Betrieb können diese Log-Ausgaben zwar gelesen werden, allerdings ist deine Simulation des laufenden Betriebs innerhalb der Codeanalyse nicht möglich.
Darüber hinaus müsste erkennbar sein, wo die Grenzen zwischen den einzelnen Aktionen sind, sodass bewertet werden kann, ob eine Log-Ausgabe für eine Aktion getätigt wird.
Aufgrund des semantischen Aufbaus der einzelnen Aktionskontexte und der Vielzahl an Implementierungsmöglichkeiten zum Ausgeben von Log-Informationen ist die Analyse hier sehr komplex und wird im Rahmen dieser Arbeit nicht berücksichtigt.

Ein Möglichkeit, die Sicherheit eines Programms innerhalb einer Codeanalyse zu bewerten, ist die Analyse auf Schwachstellen.
Hierzu kann eine \acf{OWASP}-Top-Ten-Analyse verwendet werden. 
Die \acs{OWASP}-Top-Ten ist eine Liste mit den zehn kritischsten Sicherheitsbedenken für Web-Applikationen (vgl. \cite{Ow2020}).
Dadurch können potentielle Sicherheitslücken innerhalb des Programms aufgedeckt werden.
Neben der \acs{OWASP}-Top-Ten gibt es weitere Indizes für Sicherheitslücken oder Problemstellen in Software, die ebenfalls verwendet werden können.

\subsection{Wartbarkeit}
Die Wartbarkeit beschreibt laut \cite{ISO-25010} die Effektivität und Effizienz, mit der sich Modifikationen oder Korrekturen umsetzen lassen.
Dazu gehört unter anderem die Auftrennung des Programms in Module und die entsprechende Wiederverwendbarkeit dieser Module.
Da die Auftrennung des Programms in einzelne Module entlang der semantischen Grenzen geschieht, ist dieser Aspekt nur schwer zu analysieren.
Durch das Zählen von Passagen mit doppeltem Code kann allerdings eine Aussage über die Wiederverwendbarkeit von Funktionen und Modulen getroffen werden.

Ein weiterer Bereich ist die Analysierbarkeit und Modifizierbarkeit.
Diese Aspekte beschreiben den Grad, zu dem Änderungen einen Einfluss auf die Korrektheit des Programms haben beziehungsweise voraussichtlich haben werden.
Um entsprechende Aussagen tätigen zu können, ist es wichtig, die einzelnen Programmteile mit ihren Funktionen und eventuellen Seiteneffekten zu verstehen.
Hierbei hilft, wie oben beschrieben, die Einhaltung von Stilrichtlinien und Konventionen, die innerhalb einer statischen Codeanalyse sehr gut gemessen werden kann.

Zur Analysierbarkeit gehört außerdem das Wissen um den Code.
Je komplexer der Code ist, desto schwerer wird es, ihn zu verstehen.
Die Komplexität lässt sich dabei innerhalb einer statischen Codeanalyse beispielsweise mit der McCabe-Metrik messen (vgl. \cite{MC1976}).

Auch die Verteilung von Wissen um den Code innerhalb des Entwicklungsteams gehört zur Analysierbarkeit.
Je weniger Teammitglieder sich in einem Teil des Codes auskennen, desto geringer ist das Verständnis des Codes.
Wenn es soweit kommt, dass sich nur noch ein Teammitglied in einem Teil des Codes auskennt, besteht ein Wissensmonopol.
Sollte es dazu kommen, dass dieses Teammitglied beispielsweise auf Grund von Krankheit oder Urlaub nicht erreichbar ist, müssen sich die anderen Teammitglieder erneut einarbeiten, was sich negativ auf die Analysierbarkeit auswirkt.

\subsection{Portierbarkeit}
Die Portierbarkeit beschreibt, wie gut sich ein Programm von einem System auf ein anderes transferieren lässt.
Die Systeme können sich dabei beispielsweise in der verbauten Hardware, der Laufzeitumgebung oder der Prozessorarchitektur unterscheiden.
Da es sich bei dem Code, den coderadar analysieren kann, um Java-Code handelt, sind die Programme automatisch weitestgehend unabhängig vom Betriebssystem, da es für unterschiedliche Betriebssysteme unterschiedliche Ausführungsumgebungen gibt.
Für Unterschiede in Betriebssystemen wie unterschiedliche Separatoren in Dateipfaden bietet Java ebenfalls Lösungen.
Die verbaute Hardware spielt an der Stelle für das Programm lediglich leistungstechnisch eine Rolle, da die Laufzeitumgebung von Java die Hardwarestruktur entsprechend abstrahiert.

Ein weiterer Aspekt in der Portierbarkeit ist die Installierbarkeit.
Sie beschreibt den Grad der Effektivität und Effizienz, mit dem das Programm installiert beziehungsweise deinstalliert werden kann.
Dies ist immer vom Programm selber und seinen Abhängigkeiten abhängig.
Es gibt verschiedene Möglichkeiten, ein Java-Programm auszuliefern.
Zentral ist dabei aber immer ein Java-Archiv, welches über die Konsole ausgeführt werden kann.
Entsprechend muss eine Java-Laufzeitumgebung installiert sein, damit das Programm ausgeführt werden kann.
Dieses Archiv kann beispielsweise innerhalb eines Docker\footnote{\url{https://www.docker.com/}} Images verpackt werden, was zusätzlich noch eine Installation von Docker erfordert.
Alternativ kann das Java-Archiv auf einen Web-Applikationsserver deployt werden, was wiederum die Installation eines solchen Applikationsservers erfordert.
Die Installierbarkeit ergibt sich somit nicht nur aus dem Programm selbst, sondern auch aus den jeweiligen Abhängigkeiten und der Auslieferungsform.
Entsprechend ist es nur schwer möglich, Aussagen über die Installierbarkeit zu treffen.

Die Austauschbarkeit des Programms beschreibt den Grad, zu dem das Programm ein anderes Programm, welches demselben Zweck dient, in derselben Umgebung ersetzen kann.
Um hierzu eine Aussage treffen zu können, wird Kenntnis über das zu ersetzende Programm benötigt.
Daher wird dieser Aspekt im Rahmen dieser Arbeit vernachlässigt.

\subsection{Auswahl der Qualitätskriterien}
\label{Auswahl_Kriterien}
Wie oben beschrieben, eignen sich nicht alle Aspekte aus \cite{ISO-25010} zur Bewertung der Codequalität innerhalb der Codeanalyse.
In diesem Abschnitt werden die Aspekte vorgestellt, die im Rahmen dieser Arbeit als Kriterien für qualitativ hochwertige Software verwendet werden sollen.
Die im Folgenden aufgelisteten Metriken stammen aus \cite{Ch2021} und \cite{So2021}.

\paragraph{Zuverlässigkeit}
Die Zuverlässigkeit des Programms wird im Rahmen dieser Arbeit unter anderem anhand der Testabdeckung gemessen.
Der oben beschriebene Fall, dass einige Tests die Funktionsweise des zu testenden Codes nicht korrekt prüfen, wird hier nicht berücksichtigt.
Es wird davon ausgegangen, dass die geschriebenen Tests zur Überprüfung der Funktionsweise geeignet sind.
Die gefundenen Bugs und Code-Smells und der entsprechend geschätzte Aufwand zur Behebung dieser fließen ebenfalls in die Bewertung der Zuverlässigkeit mit ein.

Die Metriken, die für die Messung der Zuverlässigkeit verwendet werden, sind folgende:
\begin{itemize}
	\item $test\_success\_density$\\
	Die $test\_success\_density$ gibt den Anteil erfolgreicher Tests in einer Software an.
	Je mehr Tests fehlschlagen, desto unzuverlässiger ist der Code.
	\item $uncovered\_lines$\\
	$uncovered\_lines$ gibt an, wie viele Programmzeilen nicht im Rahmen von Tests ausgeführt werden.
	Sollten diese Zeilen einen Fehler beinhalten, kann dieser nicht durch Tests gefunden werden.
	\item $line\_coverage$\\
	Die $line\_coverage$ beschreibt den Anteil an Zeilen, die durch Tests abgedeckt sind.
	\item $coverage$\\
	$coverage$ beschreibt eine Mischung aus Zeilenüberdeckung und Bedingungsüberdeckung und gibt so noch besser Aufschluss darüber, welcher Code durch Tests abgedeckt ist.
	\item $effort\_to\_reach\_maintainability\_rating\_a$ % TODO existiert die Metrik?
	\item $code\_smells$\\
	$code\_smells$ sind potentielle Problemstellen im Code.
	An diesen Stellen ist der Code verwirrend oder schwer zu verstehen und zu warten.
	Diese Problemstellen müssen nicht zwangsweise zu Fehlern führen, sind aber Stellen, auf die der Entwickler ein besonderes Augenmerk richten sollte, da sie zu unvorhergesehenem Verhalten führen können.
	\item $bugs$\\
	$bugs$ sind Fehler im Programmcode, die einer direkten Behebung bedürfen.
	Diese Fehler führen dazu, dass das Programm abstürzt oder falsche Aktionen ausführt.
	\item $reliability\_rating$\\
	Das $reliability\_rating$ bezieht sich auf die Anzahl und die Schwere der gefundenen Probleme.
	Die Schwere geht dabei von \textit{BLOCKER}, ein Problem welches sofort behoben werden muss, da es zum Absturz des Systems führen kann, bis \textit{MINOR}, was Qualitätsmängel beschreibt, die die Entwicklerproduktivität beeinflussen.
	Zu ersterem gehören unter anderem Speicherlecks, zu letzterem gehören beispielsweise zu lange Zeilen, die das Lesen des Codes erschweren.
	\item $violations$\\
	In den $violations$ werden alle Arten von Problemstellen unabhängig von ihrer Schwere zusammengefasst.
	\item $lines\_to\_cover$\\
	$lines\_to\_cover$ beschreibt die Anzahl an Code-Zeilen, die durch Tests abgedeckt werden müssen.
	\item $sqale\_rating$\\
	Das $sqale\_rating$ beschreibt die Zeit die anteilig zur gesamten Entwicklungszeit, die notwendig ist, um technische Schulden im Projekt auszugleichen.
\end{itemize}

\paragraph{Sicherheitsschwachstellen}
Im Rahmen der Analyse der Sicherheit des Programms wird eine Analyse auf mögliche Schwachstellen durchgeführt.
Zu diesen Schwachstellen gehören unter anderem Aspekte aus den \acs{OWASP}-Top-Ten, kommunikationsspezifische Schwachstellen wie offene Cross-Origin-Einstellungen, Sicherheitslücken aus der \acf{CWE} oder sprachspezifische Schwachstellen wie Code-Injektion bei dynamischer Code-Ausführung.

Cross-Origin-Einstellungen sorgen dafür, dass Anfragen an einen Server nur von bestimmten Adressen aus erlaubt sind.
Dadurch kann beispielsweise verhindert werden, dass ein dritter Dienst auf Daten aus dem Speicher des Browsers zugreift und so Anfragen im Namen des Nutzers stellt.

Die \acs{CWE} ist eine Auflistung bekannter Sicherheitslücken in Systemen, Frameworks und Sprachen.
Für viele dieser Sicherheitslücken existieren bereits Lösungen, für andere müssen eigene Lösungen implementiert werden.

Bei der dynamischen Ausführung von Code kann zur Zeit der Kompilierung nicht gewährleistet werden, welche Art von Objekt verwendet wird, dies steht erst zur Ausführungszeit fest.
Ein Angreifer könnte an dieser Stelle nun ein manipuliertes Objekt injizieren und so die Funktion der Software beeinflussen.

Sollten entsprechende Schwachstellen vorhanden sein, senkt dies die Codequalität an dieser Stelle deutlich.

Zur Bewertung werden hier die gefundenen \textit{vulnerabilities} verwendet.
Eine \textit{vulnerability} bezeichnet dabei eine Stelle im Code, die eine Möglichkeit für einen Angriff bietet.

\paragraph{Wiederverwendbarkeit}
Zur Bewertung der Wiederverwendbarkeit von Code innerhalb des Programms wird die Anzahl von doppeltem Code bewertet.
Doppelter Code deutet darauf hin, dass Funktionen innerhalb des Programms hätten zusammengefasst werden können, wodurch potentiell weniger Fehlerquellen bestehen und die Komplexität reduziert werden kann.
Auch die Dokumentation von Methoden, die potentiell wiederverwendet werden können, trägt einen Teil dazu bei, dass besagte Wiederverwendung stattfindet.

Die Wiederverwendbarkeit wird im Rahmen dieser Arbeit mit folgenden Metriken gemessen:

\begin{itemize}
	\item $duplicated\_lines\_density$\\
	Die $duplicated\_lines\_density$ beschreibt den Anteil von sich wiederholenden Code-Zeilen im Vergleich zum gesamten Code.
	Je öfter, gleicher oder ähnlicher Code erneut geschrieben wurde, desto schlechter sind Teile des Programms wiederverwendbar.
	\item $public\_undocumented\_api$ % TODO existiert diese Metrik
	\item $MissingJavadocMethod$
	Damit Code wiederverwendet wird, muss schnell und einfach erkennbar sein, welche Funktion ein bestimmter Teil des Codes erfüllt.
	Dies kann durch eine passende Dokumentation des Codes, der potentiell wiederverwendet werden kann, erleichtert werden.
	$MissingJavadocMethod$ misst, wie oft diese Dokumentation nicht vorhanden ist. 
\end{itemize}

\paragraph{Analysierbarkeit}
Die Analysierbarkeit ergibt sich im Rahmen dieser Arbeit aus dem Grad der Einhaltung von Stilrichtlinien und Konventionen.
Es wird davon ausgegangen, dass nonkonformer Code schwerer zu lesen, zu verstehen und entsprechend zu analysieren ist.
Die Komplexität des Codes und die Dokumentation spielen hier ebenfalls eine Rolle.

Um die Analysierbarkeit bewerten zu können, wird unter anderem die \textit{$cognitive\_complexity$} herangezogen. 
Die \textit{$cognitive\_complexity$} beschreibt die Komplexität einer Methode.
Die Berechnung ist an die McCabe-Metrik angelehnt, der Wert ergibt sich aus der Anzahl gewisser Schlüsselwörter innerhalb einer Methode.
Darüber hinaus werden viele der von Checkstyle bereitgestellten Metriken verwendet, die sich mit der Einhaltung von Stylingrichtlinien befassen.
Dazu gehören beispielsweise \textit{$MissingJavadocMethod$}, \textit{$MethodName$} oder \textit{$ClassName$}.
Letztere überprüfen, dass Namen für Bezeichner, beispielsweise Methodennamen oder Klassennamen, einem gewissen Schema entsprechen.
Es kann zwar nicht validiert werden, dass der Name des Bezeichners der Funktion des selbigen entspricht, allerdings erleichtert dieses Schema generell die Lesbarkeit.

\paragraph{Komplexität}
Die Komplexität eines Codeblocks oder einer Funktion kann mit der McCabe-Metrik gemessen werden.
Die Metrik berechnet für eine Methode einen Komplexitätswert, welcher wie folgt zu interpretieren ist:

\begin{itemize}
	\item <10: niedrige Komplexität
	\item 11 - 20: mittlere Komplexität
	\item 21 - 50: hohe Komplexität
	\item >50: sehr hohe bis undurchschaubare Komplexität
\end{itemize}

Ein hoher Wert hat entsprechend einen negativen Effekt auf die Analysierbarkeit.
Neben der McCabe-Metrik werden auch noch andere Komplexitätsmetriken verwendet.

Um die Komplexität zu messen, gibt es mehrere Möglichkeiten:

\begin{itemize}
	\item $cognitive\_complexity$
	\item $BooleanExpressionComplexity$\\
	Die $BooleanExpressionComplexity$ bezieht sich auf die Komplexität boolescher Ausdrücke.
	Durch Verschachtlungen von Negationen, Und- und Oder-Ausdrücken können diese teils sehr komplex werden.
	Da diese Ausdrücke häufig in \textit{if}- oder \textit{switch}-Abfragen für die Entscheidung verwendet werden, welcher Zweig eines Programms durchlaufen werden soll, ist es wichtig, dass sie gut zu verstehen sind.
	\item $ClassFanOutComplexity$\\
	Die $ClassFanOutComplexity$ beschreibt die Anzahl an Abhängigkeiten einer Klasse oder eines Interface.
	Jede Abhängig kann dazu führen, dass mehr Code ausgeführt wird, der potentiell zum Verständnis der aktuellen Funktion notwendig ist.
	Je mehr Abhängigkeiten eine Klasse oder ein Interface hat, desto höher ist also auch die Komplexität.
	\item $CyclomaticComplexity$\\
	Die $CyclomaticComplexity$ misst die McCabe-Komplexität.
	\item $NPathComplexity$\\
	Die $NPathComplexity$ ist eine Erweiterung der $CyclomaticComplexity$, bei der stärker auf die Kombination boolescher Ausdrücke eingegangen wurde.
	\item $JavaNCSS$\\
	$JavaNCSS$ beschreibt die Anzahl an Anweisungen innerhalb einer Klasse oder Methode.
	Je mehr Anweisungen vorhanden sind, desto höher ist die Komplexität.
\end{itemize}

\paragraph{Wissensmonopole}
Wie oben beschrieben, sorgen Wissensmonopole dafür, dass Codeverständnis gegebenenfalls neu erarbeitet werden muss.
Grade im Zusammenhang mit komplexem Code ist dies ein Problem.
Durch die Verwendung von Kommentaren und weiterer Dokumentation kann Wissensmonopolen ein Stück weit entgegengewirkt werden.
Wissensmonopole in komplexem Code haben dementsprechend einen negativen Einfluss auf die Analysierbarkeit.

\chapter{Projektkontext}
\label{Projektkontext}
Dieses Kapitel beschäftigt sich mit der Aufarbeitung der Problemstellung.
Dazu wird zunächst in Abschnitt \ref{Problembeschreibung} das Problem genauer ausformuliert.
Anschließend wird in Abschnitt \ref{Kontext} das Problem in den Kontext von coderadar eingeordnet.
Auf dieser Basis werden dann in Abschnitt \ref{Anforderungen} die Anforderungen an die zu entwickelnden Erweiterungen in coderadar gestellt.
Abschließend erfolgt die wissenschaftliche Einordnung der Arbeit in bereits bestehende Werke.

\section{Problembeschreibung}
\label{Problembeschreibung}
Zwei Eigenschaften von Entwicklern sind nach \cite{WCSP1996}, dass sie faul und hochmütig sind.
Zum einen halten sie ihren eigenen Code oft für qualitativ sehr gut und zum anderen wollen sie aufgrund ihrer Faulheit bereits geschriebenen Code nicht noch einmal bearbeiten müssen.

Dazu kommt, dass Projekte oft unter Zeitdruck oder mit nur sehr geringem Budget entwickelt werden.
Nach einer Studie von \cite{KPME2002} wurden die Zeitaufwände für etwa ein Drittel der untersuchten Projekte zu gering eingeschätzt, lediglich knapp die Hälfte der untersuchten Projekte hatten einen geringeren zeitlichen Aufwand als zu Beginn geschätzt.
Entsprechend fällt auch oft die Budgeteinschätzung aus, da die Zeitaufwände der Entwickler und entsprechende Lizenzkosten einen großen Anteil an den Entwicklungskosten ausmachen.

Dies führt dazu, dass oft wenig Zeit dafür bleibt, darauf zu achten, dass der geschriebene Code qualitativ hochwertig ist.
Stattdessen wird oft die schnellere, dafür meist aber auch unsauberere Variante bevorzugt.
Dazu gehört, dass keine Dokumentation, beispielsweise über JavaDoc, erstellt wird, dass mehrere fachlich nicht zusammengehörende Funktionalitäten in einer Klasse implementiert werden oder dass einheitliche Stylingrichtlinien außer acht gelassen werden. 

Wie bereits in Abschnitt \ref{Motivation} erwähnt, steigt dadurch der Aufwand, der zum Verstehen der Software notwendig ist.
Somit steigt auch der Aufwand für Teams, die mit der Wartung der Software betraut sind, da die Einarbeitungszeit in die Software höher ist.
Somit steigen auch die Kosten für die entsprechende Projektphase.

Mit der Hilfe von Analysewerkzeugen wie beispielsweise coderadar (vgl. \ref{Kontext}) ist es möglich, entsprechende unsaubere Varianten zu finden.
Die Herausforderung an dieser Stelle ist, wie eingangs beschrieben, Entwickler dazu zu bringen, direkt qualitativ hochwertigen Code zu schreiben.
Dies dauert zwar erfahrungsgemäß etwas länger, spart dann aber den Aufwand, den Code ein weiteres Mal bearbeiten zu müssen, um die Qualität des Codes zu steigern, sodass im Endeffekt Zeit gespart wird.

\section{Kontext coderadar}
\label{Kontext}
coderadar ist ein Analysewerkzeug für Java-Code.
Es dient dazu, automatisiert Codeanalysen auf dem Versionskontrollsystem durchzuführen.
Die Ergebnisse dieser Codeanalysen werden in Form von Metriken festgehalten, die dem Entwicklungsteam bereitgestellt werden.
Darüber hinaus ermöglicht coderadar eine Ansicht der Metriken je Commit, sodass frühere Projektversionen betrachtet werden können.

coderadar verwendet intern verschiedene Plugins zur Codeanalyse.
Bisher sind ein Checkstyle\footnote{\url{https://github.com/checkstyle/checkstyletext}}- und ein \acf{LOC}-Plugin implementiert.
Das Checkstyle-Plugin ist über die Angabe einer Checkstyle-Konfigurationsdatei konfigurierbar.
Ein Vorteil von Checkstyle an dieser Stelle ist, dass Checkstyle im Gegensatz zu anderen Analysewerkzeugen wie beispielsweise SonarQube\footnote{\url{https://github.com/SonarSource/sonarqube}} dateibasiert arbeitet.
Dadurch ist es möglich, den Dateiinhalt aus einem Commit zu laden und zu analysieren, ohne das gesamte Projekt berücksichtigen zu müssen.

Die Architektur von coderadar erlaubt es, zusätzlich zu den bereits bestehenden Analyse-Plugins eigene Plugins zu schreiben.
Diese können per Anwahl einer Checkbox in der Benutzeroberfläche für ein Projekt zu- oder abgewählt werden.
Damit im Rahmen dieser Arbeit ein Vergleich zwischen den einzelnen Projekten möglich ist, sollen im Rahmen der Fallstudie später alle verfügbaren Plugins verwendet werden.

Neben den Möglichkeiten zur Codeanalyse bietet coderadar eine Nutzerverwaltung.
Ein Nutzer kann ein Projekt anlegen und analysieren lassen.
Dazu werden eine GitHub\footnote{\url{https://github.com}}-URL, ein Projektname und, falls gewünscht, ein Start- und ein Enddatum für die Analyse angegeben.
Im nächsten Schritt können dann die zu verwendenden Analyse-Plugins ausgewählt werden.
Zusätzlich wird ein Muster für zu analysierende Dateien angegeben.
So können bestimmte Dateien von der Analyse ausgeschlossen werden, beispielsweise ist es nicht sinnvoll, die Testabdeckung innerhalb der Implementierung der Tests zu messen.
coderadar untersucht dann alle Commits im genannten Zeitraum auf Dateien, die dem angegebenen Muster entsprechen.
Wird eine entsprechende Datei gefunden, wird sie mit den konfigurierten Analyse-Plugins untersucht, und die gemessenen Metrikwerte werden zu den Metrikwerten des Commits hinzugefügt.
Ein Nutzer kann ein erstelltes Projekt auch für andere Nutzer zur Kollaboration freigeben.

Nachdem coderadar ein Projekt geclont und analysiert hat, gibt es verschiedene Visualisierungen für die Ergebnisse.
Zum einen können die Rohdaten der Metriken je Commit angezeigt werden.

Darüber hinaus können die Metrikwerte eines Commits in einer \glqq City-View\grqq{} angezeigt werden (vgl. Abbildung \ref{city_view}).
Dabei wird für jede Änderung in einem Commit ein \glqq Haus\grqq{} erstellt.
Das Aussehen eines solchen Hauses hängt dabei von den vier Faktoren Länge, Breite, Höhe und Farbgebung ab.
Jeder dieser Faktoren lässt sich dabei mit dem Wert einer Metrik belegen.
Die City-View kann sowohl einen Commit als auch zwei Commits vergleichend anzeigen.
Bei der vergleichenden Ansicht besteht die Möglichkeit, entweder beide City-Views nebeneinander oder beide Views ineinander anzuzeigen.

Neben der City-View gibt es auch eine \glqq Dependency-Map\grqq{} (vgl. Abbildung \ref{dependency_map}).
Die Dependency-Map zeigt die Ordnerstruktur des Projektes sowie die Abhängigkeiten der einzelnen Module untereinander an.
Die einzelnen Unterordner lassen sich dabei aufklappen, sodass auch innerhalb eines Unterordners die Abhängigkeiten visualisiert werden.
Auch hier ist sowohl eine Einzelansicht eines Commits als auch eine vergleichende zweier Commits möglich.
Änderungen zwischen den zwei Commits werden entsprechend farblich markiert.

coderadar listet die einzelnen Commits entweder in einer Liste oder in der Baumansicht (vgl. Abbildung \ref{tree_view}) auf.
Die Liste ist nach Erstellungsdatum des Commits sortiert. 
In der Baumansicht werden die Commits anhand der Branches angezeigt, denen sie zugeordnet sind.
Zusätzlich bietet coderadar die Funktion, für einen ausgewählten Commit die Ordnerstruktur und den Dateiinhalt anzuzeigen.

Ein Nutzer kann auch ein Team anlegen.
Innerhalb eines Teams gibt es Mitglieder und Administratoren.
Ein Administrator kann im Namen des Teams ein Projekt anlegen und analysieren.
So ist das Projekt nicht direkt von dem Nutzer abhängig.
Löscht der Nutzer also seinen Account oder verlässt das Team, kann das Team mit dem Projekt immer noch weiterarbeiten.
Ein Nutzer kann dabei auch mehreren Teams angehören.

\section{Anforderungen}
\label{Anforderungen}
In diesem Abschnitt werden die Anforderungen an die im Rahmen dieser Arbeit durchzuführenden Ergänzungen erarbeitet.
An dieser Stelle werden dabei lediglich die funktionalen Anforderungen berücksichtigt, da zum einen die nichtfunktionalen Anforderungen zu einem Teil durch die bestehende Basissoftware abgedeckt sind und zum anderen die nichtfunktionalen Anforderungen für die weitere Arbeit nicht von Bedeutung sind.
Die Identifikation der einzelnen Anforderungen erfolgt über einen Buchstaben und eine Nummer.
Der erste Buchstabe beschreibt dabei, welcher Teil der Anwendung diese Anforderung erfüllen soll.
\glqq A\grqq{} steht dabei für den Analyseprozess, \glqq B\grqq{} für Backend, \glqq F\grqq{} für Frontend.
Die Nummer dient zur Identifikation einer Anforderung im jeweiligen Teilbereich und wird hochgezählt.
Die Anforderungen an den Analyseprozess und die anderen Funktionen des Backends werden hier getrennt betrachtet, da die Ergänzung des Analyseprozesses um die in Abschnitt \ref{Auswahl_Kriterien} gestellten Kriterien Abwägungen zwischen verschiedenen Lösungsansätzen enthalten und somit mit einigem Aufwand verbunden sein werden.

\paragraph{A.1}
Der Analyseprozess für die einzelnen Commits muss dahingehend ergänzt werden, dass der ganze Projektstand an diesem Commit analysiert werden kann und nicht nur die geänderten Dateien.
Dies dient dazu, dass auch Werkzeuge wie SonarQube verwendet werden können, die weitere Metriken bereitstellen.

\paragraph{A.2}
Der Analyseprozess muss mit verschiedenen Java-Versionen und Build-Management-Werkzeugen umgehen können.
Speziell sind die Java-Versionen von Java 8 bis Java 11 zu berücksichtigen.
Des Weiteren sollen die Build-Management-Werkzeuge Gradle und Maven berücksichtigt werden.

\paragraph{A.3}
Das System muss eine Möglichkeit zur Untersuchung des Reifegrades des Projekts zum Zeitpunkt des zu analysierenden Commits bieten.
Dazu wird die Testabdeckung innerhalb des Projekts bewertet. Dabei sollen sowohl die Anweisungs- als auch die Zweigüberdeckung berücksichtigt werden.

\paragraph{A.4}
Das System muss eine Möglichkeit zur Untersuchung der Sicherheit des Projekts zum Zeitpunkt des zu analysierenden Commits bieten.
Hier sollen \acs{OWASP}-Top-Ten, \acs{CWE} und weitere Ursachen für \textit{vulnerabilities} in SonarQube verwendet werden.

\paragraph{A.5}
Das System muss eine Möglichkeit zur Untersuchung der Wiederverwendbarkeit von Teilen des Projekts zum Zeitpunkt des zu analysierenden Commits bieten.
Hierzu wird das Projekt auf doppelten Code hin untersucht.

\paragraph{A.6}
Das System muss eine Möglichkeit zur Untersuchung der Analysierbarkeit des Projekts zum Zeitpunkt des zu analysierenden Commits bieten.
Hierzu soll die Einhaltung von Stilrichtlinien und Konventionen betrachtet werden.

\paragraph{A.7}
Das System muss eine Möglichkeit zur Untersuchung der Komplexität von Teilen des Projekts zum Zeitpunkt des zu analysierenden Commits bieten.
Die Bewertung findet dabei unter anderem anhand der Komplexitätsmetrik nach \cite{MC1976} statt.

\paragraph{A.8}
Das System muss eine Möglichkeit zur Untersuchung auf Wissensmonopole in Teilen des Projekts zum Zeitpunkt des zu analysierenden Commits bieten.
Dazu wird die Anzahl an Autoren einer Datei zusammen mit der Komplexität nach \cite{MC1976} verwendet.

\paragraph{B.1}
Das System muss für jeden Nutzer eine Gesamtpunktzahl, ein Level, die Punktzahl im aktuellen Level, eine Anzahl an Coins, die Liste erhaltener Badges, die Liste absolvierter Quests und die dem Nutzer zugeordneten Contributors speichern.
Ein Contributor ist dabei ein identifizierter Git-Account in einem Projekt.
Einem Nutzer können mehrere Contributors zugeordnet sein, da ein Nutzer zum einen in mehreren Projekten aktiv sein kann und zum anderen mit mehreren Git-Accounts in einem Projekt arbeiten kann.

\paragraph{B.2}
Das System muss für jeden Commit aus den Werten der einzelnen Metriken sowie der Metrikmatrix einen Score berechnen können.

\paragraph{B.3}
Das System muss für jeden Contributor eine Gesamtpunktzahl berechnen.
Diese Gesamtpunktzahl ergibt sich aus der Summe der Scores über alle Commits des Contributors.

\paragraph{B.4}
Das System muss mehrere Level verwalten.
Ein Level hat dabei einen nummerischen Bezeichner, eine Gesamtpunktzahl, die notwendig ist, um dieses Level zu erreichen und die Anzahl an Punkten, die in diesem Level notwendig ist, um das nächste Level zu erreichen.
Mit steigendem Level soll dabei die Anzahl an benötigten Punkten bis zum nächsten Level größer werden.

\paragraph{B.5}
Das System muss Aufgaben, sogenannte Quests, verwalten.
Eine Aufgabe hat einen eindeutigen Identifikator, einen Titel, einen Beschreibungstext, eine Anzahl an Punkten und eine Anzahl an Coins, die ein Nutzer für das Erfüllen bekommt.

\paragraph{B.6}
Das System muss nach der Analyse eines Commits den errechneten Score automatisch zum jeweiligen Nutzer und Contributor dazurechnen.
Bei dem Contributor wird lediglich die Gesamtpunktzahl erhöht.
Bei dem Nutzer muss zunächst die Gesamtpunktzahl erhöht werden.
Reicht die Gesamtpunktzahl aus, um das nächste Level zu erreichen, muss das Level entsprechend hochgezählt werden.
Zusätzlich muss die Punktzahl im aktuellen Level angepasst werden.
Wird ein neues Level erreicht, ist die Punktzahl im aktuellen Level die Anzahl erhaltener Punkte, abzüglich der Punkte, die für den Level-aufstieg nötig waren.
Wird kein neues Level erreicht, werden die erreichten Punkte auf die Punkte im aktuellen Level addiert.

\paragraph{B.7}
Das System muss für jeden Nutzer eine Liste an Personalisierungen speichern.
Zu speichern sind ein Farbschema für die Benutzeroberfläche, eine Liste anzuzeigender Badges und das aktuelle Ziel des Nutzers.

\paragraph{F.1}
Das System muss dem Nutzer sein aktuelles Level, seine Punktzahl im aktuellen Level und die Punktzahl, die im aktuellen Level benötigt wird, in der generellen Übersicht anzeigen.

\paragraph{F.2}
Das System soll eine Übersicht über verschiedene Bestenlisten anzeigen.

\paragraph{F.3}
Das System muss für jedes Projekt eine Bestenliste in der Übersicht der Bestenlisten anzeigen.
Diese Bestenliste wird über die Gesamtpunktzahl der einzelnen Contributors erstellt.
Ist ein Contributor einem Nutzer zugeordnet, muss auch dessen Nutzername angezeigt werden.

\paragraph{F.4}
Das System muss eine Bestenliste über alle Projekte in der Übersicht der Bestenlisten anzeigen.
Dazu wird für jedes Projekt ein Score errechnet.
Dieser ergibt sich aus der Summe aller Gesamtpunktzahlen aller Contributors des Projekts, geteilt durch die Anzahl an Contributors.
In dieser Bestenliste muss jeweils der Projektname und die Punktzahl angezeigt werden.

\paragraph{F.5}
Das System muss eine Bestenliste über alle Nutzer in der Übersicht der Bestenlisten anzeigen.
Dazu wird jeweils die Gesamtpunktzahl des Nutzers, geteilt durch seine Anzahl an Projekten verwendet.
In der Bestenliste muss je Nutzer der Name, das Level und die Anzahl an Projekten dargestellt werden.
Zusätzlich werden noch, wenn verfügbar, der Titel und die Badges des Nutzers angezeigt.

\paragraph{F.6}
Das System muss in einer gesonderten Ansicht die Quests anzeigen.
Dabei sollen in einem Abschnitt die noch nicht abgeschlossenen und in einem anderen Abschnitt die bereits abgeschlossenen Quests des Nutzers aufgelistet werden.

\paragraph{F.7}
Das System muss verschiedene Einstellungsmöglichkeiten für Personalisierungen bieten.
Diese werden mit steigendem Level des Nutzers freigeschaltet.
Der Nutzer muss hier ein Farbschema, eine Liste an Badges und sein aktuelles Ziel einstellen können.

\section{Wissenschaftliche Einordnung}
\label{Wissenschaftliche_Einordnung}
Die Idee, Gamification-Elemente im Zusammenhang mit Code-Qualität zu nutzen, ist nicht neu.
Ein Ansatz ist SonarQuest\footnote{\url{https://www.viadee.de/loesungen/java/sonarquest}}.
SonarQuest nutzt Analyseergebnisse von SonarQube\footnote{\url{https://www.sonarqube.org/}}, um auf Basis eines vordefinierten Regelwerks eine Menge an Kennzahlen und Wartungsaufgaben zu erstellen.
Jeder Nutzer wird durch einen Avatar repräsentiert.
Wie in herkömmlichen Rollenspielen kann ein Nutzer seinen Avatar mit Artefakten ausstatten und der Avatar kann eigene Fähigkeiten ausbilden.
SonarQuest wird dabei immer von einem Gamemaster begleitet, der zu den definierten Wartungsaufgaben jeweils eine Geschichte erstellt.
Daraus resultiert dann jeweils eine Quest, die von einem Spieler angenommen werden kann.
Für das Erfüllen einer Quest und damit einer Wartungsaufgabe bekommt ein Nutzer Gold und Erfahrungspunkte als Belohnung. 
Neben der normalen Belohnung für eine Quest kann der Gamemaster auch Sonderaufgaben und Boni verteilen, um Aspekte wie Teamwork oder Termineinhaltung besonders zu belohnen.\cite{SonarQuest}

SonarQuest ist dabei sehr stark einem klassischen Rollenspiel nachempfunden und bringt somit einigen Mehraufwand mit sich.
Zum einen müssen regelmäßig neue Quests geschrieben werden.
Dabei sollten Quests so geschrieben sein, dass ihre Geschichte den Spieler dazu motiviert, die Aufgabe zu erfüllen.
Laut \cite{SonarQuest} liegt diese Aufgabe jeweils beim Teamleiter.
Dies kann den Teamleiter aber abhängig von der Anzahl an Wartungsaufgaben, Tiefe und inhaltlicher Schlüssigkeit der Hintergrundgeschichten der Aufgaben und dem literarischen Talent den Teamleiter sowohl zeitlich als auch in seinen Fähigkeiten überfordern.
Zum anderen basieren die Messwerte und damit die vergebenen Belohnungen von SonarQuest ausschließlich auf den Ergebnissen der Analyse von SonarQube.
SonarQube bietet zwar eine gesamtheitliche Analyse des Projekts, wodurch beispielsweise doppelter Code auch Klassenübergreifend auffällt, allerdings wird für die Analyse mit SonarQube immer das gesamte Projekt benötigt.
Es ist dadurch deutlich komplexer, Unterschiede zwischen zwei Commits herauszustellen oder das Projekt an einem früheren Zeitpunkt in der Entwicklungshistorie zu untersuchen.
SonarQube soll zwar auch für die Analyse der Commits verwendet werden, allerdings ist ein erheblicher Mehraufwand notwendig, um die Historie der Commits zu berücksichtigen.
Außerdem sollen neben SonarQube noch weitere Quellen für Messwerte verwendet werden, was in SonarQuest nicht möglich ist.
Darüber hinaus soll der Aufwand für das regelmäßige Schreiben der Quests wegfallen.
Stattdessen sollen im Vorfeld einige Quests definiert werden, die die Entwickler dann erfüllen können.
Eine Geschichte zu den einzelnen Quests soll es nicht geben.

Ein weiterer Ansatz wird in \cite{Prause2012} vorgestellt. 
Prause et al. haben dazu zwei Gruppen von Studenten untersucht, die jeweils ein ähnliches Softwareprojekt nach agilem Vorgehen in Pair Programming entwickeln sollten.
Beide Gruppen wurden dabei jeweils von Lehrern begleitet.
Der Versuch war dabei in zwei Phasen unterteilt.
In der ersten Phase wurden lediglich Qualitätsmetriken gesammelt und ausgewertet, die Teilnehmer wurden darüber jedoch erst ab der zweiten Phase informiert.
In dieser zweiten Phase wurden die Teilnehmer in einer täglichen Mail sowie in Meetings über den aktuellen Zwischenstand und ihren Punktestand informiert.
Zusätzlich dazu wurden Informationen verschickt, die bei der Verbesserung der Code-Qualität helfen sollten.
Nach Abschluss des Versuchs sollte zudem der Entwickler mit der besten Platzierung einen Amazon-Gutschein erhalten.
Die Bewertung einer Datei fand dabei auf einer Skala von +10 bis -10 statt.

Als Basis für die Bewertung wurde allerdings lediglich die Vollständigkeit des JavaDoc herangezogen.
Dies ist allerdings nur ein Aspekt für qualitativ guten Code nach \cite{ISO-25010}, auf Aspekte wie Analysierbarkeit, Sicherheit oder Zuverlässigkeit wurde an dieser Stelle nicht eingegangen.
Die Punktzahl eines Nutzers ergab sich dann daraus, ob er mehr zu positiv oder negativ bewerteten Dateien beigetragen hat.
Zudem weist \cite{Prause2012} selbst die Kritik auf, dass die Bewertungsformel für die Punkte der Teilnehmer undurchsichtig war und somit die Teilnehmer nicht beziehungsweise nur schwer nachvollziehen konnten, wie sie ihre Bewertung verbessern konnten.
Das Pair Programming wird als weiterer Kritikpunkt aufgeführt, da zum einen nur ein Teilnehmer die Anerkennung für die Arbeit beider Partner bekommt und zum anderen für den eigenen Account Beiträge von anderen Entwicklern eingereicht werden können.
Im Rahmen dieser Arbeit sollen mehrere Aspekte aus \cite{ISO-25010} verwendet werden. Außerdem soll die Bewertungsformel einsehbar und verständlich sein, sodass das Ergebnis nachvollziehbar ist.
Die Verwendung von Pair Programming soll im Rahmen dieser Arbeit nicht berücksichtigt werden, stattdessen wird davon ausgegangen, dass der Code, der von einem Contributor eingereicht wurde, auch von diesem geschrieben wurde.

Ein weiterer Versuch wurde von \cite{PJ2015} unternommen.
Ziel dieses Versuchs war es, Gamification einzusetzen, um Stylingrichtlinien durchzusetzen.
Im Rahmen dieses Versuchs sollten zwei Entwicklerteams jeweils ähnliche Software implementieren. 
Als Basis für die Bewertung der Entwickler diente in diesem Versuch eine Punktzahl, die sich aus den mit Checkstyle gemessenen Verstößen gegen die vorgeschriebenen Stylingrichtlinien ergaben.
Die Entwickler wurden dabei sowohl einzeln als auch als Team bewertet.
Der Versuch war in zwei Phasen aufgeteilt, in der ersten Phase bekam Team A Rückmeldung über die Leistung sowohl des Teams als auch der einzelnen Personen, in der zweiten Phase bekam Team B dieses Feedback.
Ein Ergebnis des Versuchs ist, dass beide Teams in der Zeit, in der sie Feedback bekamen, deutlich weniger Verstöße gegen die Stylingrichtlinien zu verzeichnen hatten.
Auffällig ist auch, dass die Anzahl an Verstößen bei Team A nach Ende der Feedback-Phase wieder zugenommen hat.
Auch war für die Bewertung des einzelnen Entwicklers sowie des jeweiligen Entwicklerteams die Anzahl an Verstößen lediglich zu Projektende von Bedeutung.
Dies führte dazu, dass Team A kurz vor Ende seiner Feedback-Phase viel Arbeit in die Reduktion der Anzahl an Verstößen gesteckt hat.

Im Rahmen dieser Arbeit soll die Code-Qualität über den gesamten Zeitraum beobachtet und bewertet werden.
Der Fokus soll nicht auf einer möglichst hohen Codequalität sondern auf dem Lernerfolg der Entwickler liegen.
Daher wird die Codequalität kontinuierlich betrachtet und wenn möglich sollen individuelle Hilfestellungen zur Verbesserung der Codequalität gegeben werden.

\chapter{Entwurf des Lösungsansatzes}
\label{Entwurf}
In diesem Kapitel wird ein Lösungsansatz zur Integration von Gamification in coderadar zur nachhaltigen Steigerung der Codequalität entworfen.
Dazu wird zunächst in Abschnitt \ref{Codeanalyse} vorgestellt, wie die Codeanalyse in coderadar bisher durchgeführt wird und welche Herausforderungen bei der Erweiterung und der Implementierung weiterer Plugins bestehen.
Danach wird in Abschnitt \ref{Architektur} die Architektur von coderadar mit der Integration des Lösungsansatzes beschrieben.
In Abschnitt \ref{Metrikmatrix} wird dann auf Basis der Metriken aus \ref{Auswahl_Kriterien} ein Matrix zur Gewichtung der gesammelten Metriken erstellt.
Anschließend wird in Abschnitt \ref{Gamification_Elemente} der Einsatz von Gamification-Elementen ausgearbeitet.

\section{Codeanalyse}
\label{Codeanalyse}
In diesem Abschnitt wird genauer auf die Codeanalyse eingegangen.
Dazu wird zunächst in Abschnitt \ref{Analyseprozess} der Analyseprozess innerhalb von coderadar beschrieben.
Anschließend wird in Abschnitt \ref{Herausforderungen} auf besondere Herausforderungen bei der Erweiterung des bisherigen Analyseprozesses eingegangen.

\subsection{Analyseprozess}
\label{Analyseprozess}
Die Codeanalyse in coderadar erfolgt jeweils Commit- und Dateiweise.
Für jeden Commit werden die Dateien geladen, die geändert wurden.
Diese Dateien werden dann in die konfigurierten Analyse-Plugins gegeben.
Die Plugins implementieren dabei jeweils eine Analysemethode, die als Parameter den Pfad zur Datei und den Dateiinhalt bekommt.
Die Analysemethode gibt die Metriken für die Datei mit den jeweils berechneten Werten und den Fundorten für die Makel im Quellcode, die zu Abwertungen geführt haben, zurück.
Um die Bewertungen für einen Commit zu ermitteln, werden für die Metrikwerte für alle geänderten Dateien in diesem Commit zusammengerechnet.
Dadurch, dass diese Analyse für jeden Commit durchgeführt wird, entsteht auch eine Historie über die Commits.

\subsection{Herausforderungen}
\label{Herausforderungen}
Um einige der in Abschnitt \ref{Kriterien_guter_Code} geforderten Metriken messen zu können, muss die bisher durchgeführte Analyse erweitert werden.
Ein zur Messung dieser Metriken geeignetes Werkzeug ist SonarQube\footnote{\url{https://www.sonarqube.org/}}.
SonarQube bietet mit dem SonarScanner\footnote{\url{https://docs.sonarqube.org/latest/analysis/scan/sonarscanner/}} \acf{CLI} ein Werkzeug für die Kommandozeile, um Projekte zu analysieren.
Das Ergebnis dieser Analyse wird anschließend an einen SonarQube-Server geschickt und kann dort entweder über die Benutzeroberfläche oder eine \acs{REST}-Schnittstelle eingesehen werden. 
An dieser Stelle wird SonarQube verwendet, da es zum einen weit verbreitet ist.
Laut \cite{SC2021} wurden allein in der \glqq as a Service\grqq{}-Version SonarCloud\footnote{\url{https://sonarcloud.io/}}, die ausschließlich für Open-Source-Software genutzt werden kann, bereits über 180.000 Projekte analysiert.
Dazu kommen noch von Firmen und Privatpersonen bereitgestellte Instanzen, die für Closed-Source-Software benötigt werden.
Zum anderen wird SonarQube als Standard bei der adesso SE verwendet wird.
An dieser Stelle orientiert sich diese Arbeit am Vorgehen der adesso SE, da im Rahmen der Masterarbeit, die auf dieser Arbeit aufbauen wird, bei der adesso SE ein Feldversuch zur Evaluierung der in dieser Arbeit vorgenommenen Implementierung durchgeführt werden soll.

An dieser Stelle bestehen aber auch einige Probleme.
Zum einen hält SonarQube, abgesehen von einer manuell vorzunehmenden Versionierung, nur die aktuellen Analyseergebnisse vor.
Um Analyseergebnisse von älteren Commits zu erhalten, muss für den jeweiligen Commit entweder eine Version angelegt werden oder das Projekt muss auf diesen Commit gesetzt werden.
Um an dieser Stelle auch parallele Analysen zu ermöglichen, werden jeweils neue Projekte für die einzelnen Commits angelegt, die über den Commit-Hash eindeutig identifiziert werden.

Eine weitere Herausforderung besteht darin, aus der einzelnen Datei, die in coderadar für die Analyse zur Verfügung steht, den kompletten Projektstand zu bekommen.
Hierfür muss das komplette Projekt an dem zu analysierenden Commit ausgecheckt werden.
An dieser Stelle muss eine Möglichkeit zur Vor- und Nachbereitung der Analyse der einzelnen Commits gegeben werden.
Innerhalb der Vorbereitung kann dann das jeweilige Projekt ausgecheckt und analysiert werden, in der Nachbereitung werden reservierte Ressourcen dann wieder freigegeben.

Um nun die SonarQube-Analyse durchzuführen, werden allerdings die kompilierten Dateien benötigt.
Um das Projekt kompilieren zu können, sind zunächst einige Informationen über die Projektstruktur notwendig.
Projekte verwenden teilweise Build-Management-Werkzeuge wie Gradle\footnote{\url{https://gradle.org/}} oder Maven\footnote{\url{https://maven.apache.org/}}.
Durch diese Werkzeuge können Abhängigkeiten, die über die \acf{JRE} hinaus gehen, automatisch aufgelöst werden.
Können diese Abhängigkeiten nicht aufgelöst werden, kann auch das Projekt nicht kompiliert werden.
Entsprechend können auch Tests fehlschlagen und die Metriken falsche oder keine Werte zurückgeben.
Um herauszufinden, ob und wenn ja, welches Build-Management-Werkzeug verwendet wird, kann nach bestimmten Dateien im Projektverzeichnis gesucht werden.
Gradle zeichnet sich an dieser Stelle durch eine Datei \textit{build.gradle} aus, bei Maven existiert eine \textit{pom.xml}.
Ist eine dieser Dateien im Projektverzeichnis vorhanden, können die entsprechenden Befehle zum Kompilieren des jeweiligen Build-Management-Werkzeugs verwendet werden.
Sind keine dieser Dateien vorhanden, wird der klassische Java-Befehl zum Kompilieren von Dateien verwendet.

An dieser Stelle treten ebenfalls einige Herausforderungen auf.
Mit der Zeit werden Versionen von Abhängigkeiten, des Build-Management-Werkzeugs oder von Java geändert.
Damit das Projekt weiterhin zuverlässig kompiliert werden kann, muss teilweise auf diese Versionsänderungen reagiert werden können.
Haben sich Abhängigkeiten so stark verändert, dass die im Build-Management-Werkzeug angegebene Version nicht mehr verfügbar ist, kann das Projekt auch nicht mehr kompiliert werden.
An der Stelle können dann keine Metriken über SonarQube bezogen werden.
Generell kann auf neuere Versionen in den Abhängigkeiten nicht reagiert werden, da in den Abhängigkeiten teilweise benötigte Funktionen geändert werden oder wegfallen, sodass die ursprüngliche Funktionalität der Software nicht mehr gegeben ist.
Darüber hinaus würden solche Änderungen Änderungen in der \textit{build.gradle} oder der \textit{pom.xml} erfordern und somit die Software verändern, was im Rahmen dieses Projekts nicht passieren soll.

Der Anpassung der Version des Build-Management-Werkzeugs kann im Beispiel von Gradle damit begegnet werden, dass ein Gradle Wrapper\footnote{\url{https://docs.gradle.org/current/userguide/gradle_wrapper.html}} verwendet wird.
Dieser zieht die Versionsnummer für Gradle fest, lädt diese herunter und konfiguriert sie.
Dadurch muss nicht jede benötigte Gradle-Version manuell heruntergeladen werden.
Teilweise kann es hier auch passieren, dass die Java-Version, die von Gradle verwendet wird, eine andere ist, als die, die im Projekt verwendet wird.
Dies führt dazu, dass beispielsweise die Java-Version 7 ausgelesen wird, Gradle aber die Version 8 benötigt.
Da laut \cite{OB2021} Java 8 Rückwärtskompatibel zu Java 6 und 7 ist, wird an dieser Stelle immer Java 8 verwendet wenn eine dieser drei Versionen ausgelesen wurde.

Eine Änderung in der Java-Version kann in einem Gradle-Projekt darüber erkannt werden, dass sich bestimmte Eigenschaften in der \textit{build.gradle} ändern.
Hier muss entsprechend eine Version der jeweiligen \acs{JRE} installiert sein, damit das Projekt mit der korrekten Version kompiliert werden kann.
Um die Java-Version entsprechend zu setzen, müssen die Umgebungsvariablen \textit{$JAVA\_HOME$} und \textit{$PATH$} angepasst werden.

Ein weiteres Problem besteht darin, dass einige Commits fehlerhaft beziehungsweise nicht kompilierbar sind.
Beispielsweise fehlen bei solchen Commits Abhängigkeiten oder Imports oder das Projekt kann aufgrund von Codefehlern nicht kompiliert werden.
Ein weiterer Grund können fehlschlagende Tests sein.
Gradle und Maven führen während des Kompilierens des Projekts die im Projekt konfigurierten Tests durch.
Dies ist notwendig, damit Aussagen über die Testabdeckung getroffen werden können.
Die Build-Management-Werkzeuge sind an der Stelle so eingestellt, dass das Fehlschlagen eines Tests auch den Kompilierprozess fehlschlagen lässt.
Entsprechend können diese Commits auch nicht per SonarQube analysiert werden.

Im Anschluss an das Kompilieren des Projekts wird die SonarQube-Analyse gestartet.
Das SonarScanner \acs{CLI} stellt die Analyseergebnisse nicht in Form einer Datei zur Verfügung, sondern lädt diese auf einen SonarQube-Server hoch.
Dieser Server muss neben der Datenbank für coderadar und coderadar selbst deployt werden.
Die Analyseergebnisse können dann, wie oben bereits erwähnt, über eine \acs{REST}-Schnittstelle abgefragt werden.
Damit das Anfragen der Analyseergebnisse möglich ist, muss im SonarQube-Server zunächst ein Projekt für diesen Commit angelegt werden.
Dies ist auch über die \acs{REST}-Schnittstelle möglich und muss zu Beginn einer jeden Analyse gemacht werden.
Im Anschluss an die Analyse kann das jeweilig konfigurierte Projekt dann wieder entfernt werden, um Ressourcen zu schonen.

Damit nicht für jede Datei, die im zu untersuchenden Commit geändert wurde, eine Anfrage gestellt werden muss, wird zu Beginn eine große Anfrage an den SonarQube-Server gestellt.
Die Ergebnisse dieser Anfrage werden dann nach dem jeweiligen Dateipfad aufgeschlüsselt gespeichert.
In der Analyse der jeweiligen Datei wird dann auf diese zwischengespeicherten Daten zugegriffen.
So muss nicht für jede zu analysierende Datei eine Anfrage via \acs{REST} gestellt werden, und die Analyse einer Datei ist performanter.

\section{Architektur}
\label{Architektur}
Um die weiteren geforderten Metriken erfassen zu können, werden weitere Maßnahmen zu Codeanalyse benötigt.
Dies geschieht in coderadar durch die Ergänzung weiterer Analyse-Plugins.
Dazu wird ein neues Untermodul im Modul \textit{coderadar-plugins} angelegt.
Zentraler Aspekt dieses Moduls ist die Klasse \textit{SonarScannerSourceCodeFileAnalyzerPlugin}, welches das Interface \textit{SourceCodeFileAnalyzerPlugin} implementiert.
In coderadar wird via Java Reflection über alle Klassen iteriert, die das \textit{SourceCodeFileAnalyzerPlugin}-Interface implementieren.
Für jede Klasse wird dann die \textit{analyze()}-Methode aufgerufen.
Um die Metriken von SonarQube zu bekommen, wird hier entsprechend ein neues Modul geschrieben, welches eine entsprechende Analyse durchführt.

Darüber hinaus muss jede Analyse vor- und nachbereitet werden.
Zur Vorbereitung gehört das Anlegen des SonarQube-Projekts, der Checkout des zu analysierenden Commits sowie die Analyse an sich.
Zur Nachbereitung gehört das Entfernen des SonarQube-Projekts.

Die Vor- und Nachbereitung ist jeweils ein Prozess, der von der Dateianalyse getrennt zu betrachten ist, da er nicht je Datei, sondern je Commit durchgeführt werden soll.
Aus diesem Grund wird die Vor- und Nachbereitung in eigens dafür zu erstellende Methoden ausgelagert.
Um aus Sicht des \textit{coderadar-core}-Moduls eine Unabhängigkeit zu den einzelnen Plugins herzustellen, wird an dieser Stelle in der \textit{coderadar-plugin-api} ein neues Interface \textit{WrappedAnalyzingProcess} eingeführt.
Dieses Interface schreibt jeweils eine Methode zur Vor- und Nachbereitung der Analyse vor, \textit{prepareAnalysis()} und \textit{postprocessAnalysis()}.
Im Analyseprozess wird dann zunächst über alle Implementierungen des \textit{WrappedAnalyzingProcess} iteriert und für jede Instanz wird die Methode \textit{prepareAnalysis()} aufgerufen.
Anschließend findet die Analyse des Commits, gefolgt von dem Aufruf der Methode \textit{postprocessAnalysis()} für alle Implementierungen des \textit{WrappedAnalyzingProcess}-Interface.

Des Weiteren müssen die von den einzelnen Analyse-Plugins zurückgegebenen Metrikwerte mit Hilfe einer noch zu erarbeitenden Metrikmatrix in eine absolute Punktzahl umgerechnet werden.
Diese Punktzahl muss dann dem Autor des Commits gutgeschrieben und sein Level angepasst werden.

Außerdem müssen gemäß den Anforderungen aus \ref{Anforderungen} Anpassungen in der Benutzerschnittstelle im Modul \textit{coderadar-ui} vorgenommen werden.
Um die benötigten Daten zu speichern und bereitzustellen, müssen entsprechende Anpassungen in der \acs{REST}-Schnittstelle und dem Datenbankadapter, \textit{coderadar-rest} beziehungsweise \textit{coderadar-graph}, vorgenommen werden.
Für die im Rahmen dieser Arbeit implementierten Erweiterungen müssen darüber hinaus Tests geschrieben werden.
Diese teilen sich auf in Unit-Tests, die im jeweiligen Modul, und Integrationstests, welche im Modul \textit{coderadar-test} implementiert werden.

Entsprechend der in diesem Absatz beschriebenen Änderungen wird coderadar wie im Komponentendiagramm in Abbildung \ref{component_diagram} beschrieben aufgebaut sein.
Orange eingefärbte Module werden dabei geändert, grün gefärbte Module werden hinzugefügt.

\begin{figure}[H]
	\begin{center}
		\includegraphics[width=\linewidth]{images/coderadar_components}
		\caption{Die Struktur der Komponenten in coderadar nach den Erweiterungen aus dieser Arbeit.}
		\label{component_diagram}
	\end{center}
\end{figure}

\section{Metrikmatrix}
\label{Metrikmatrix}
Um aus der Menge an Metriken, die coderadar mit der in dieser Arbeit entwickelten Erweiterung für jeden Commit sammelt, eine Summe an Punkten zu ermitteln, müssen die Ergebnisse der Metriken zusammengefasst werden.
Da beispielsweise Vulnerabilities einen deutlich stärkeren Einfluss auf die Qualität des Codes haben, müssen die einzelnen Ergebnisse der Metriken gewichtet werden.
Zur gewichteten Zusammenfassung der Metriken wird an dieser Stelle eine Metrikmatrix verwendet.
Sie multipliziert die Gewichtung der jeweiligen Metrik mit ihrem Wert und erhält in Summe eine Punktzahl für einen Commit.

Eine weitere Aufgabe der Metrikmatrix ist die Ausbalancierung der Punkte, die ein Autor für einen Commit erhalten kann.
Es darf nicht möglich sein, durch das wiederholte Ausführen bestimmter, trivialer Aktionen übermäßig viele Punkte zu erhalten, da sonst die Vergleichbarkeit zu anderen Autoren und Projektteams nicht mehr gegeben ist.
Diese Balancierung wird ebenfalls über die Gewichtung vorgenommen.

Im Folgenden ist diese Metrikmatrix in Tabellenform dargestellt: \ref{metric_matrix}

\label{metric_matrix}
\begin{longtable}{|c|c|}
	\hline
	Metrik & Gewichtung  \\ \hline
	coderadar:size:eloc:java & x \\ \hline
	coderadar:size:sloc:java & x \\ \hline
	coderadar:size:cloc:java & x \\ \hline
	coderadar:size:loc:java & x \\ \hline
	CustomImportOrderCheck & x \\ \hline
	TodoCommentCheck & x \\ \hline
	UncommentedMainCheck & x \\ \hline
	NeedBracesCheck & x \\ \hline
	DeclarationOrderCheck & x \\ \hline
	ExplicitInitializationCheck & x \\ \hline
	FinalLocalVariableCheck & x \\ \hline
	HiddenFieldCheck & x \\ \hline
	AbstractClassNameCheck & x \\ \hline
	AvoidStarImportCheck & x \\ \hline
	AvoidStaticImportCheck & x \\ \hline
	ClassDataAbstractionCouplingCheck & x \\ \hline
	ClassFanOutComplexityCheck & x \\ \hline
	CyclomaticComplexityCheck & x \\ \hline
	FinalClassCheck & x \\ \hline
	HideUtilityClassConstructorCheck & x \\ \hline
	IllegalCatchCheck & x \\ \hline
	ImportOrderCheck & x \\ \hline
	JavadocStyleCheck & x \\ \hline
	LineLengthCheck & x \\ \hline
	MagicNumberCheck & x \\ \hline
	MethodCountCheck & x \\ \hline
	MultipleStringLiteralsCheck & x \\ \hline
	NewlineAtEndOfFileCheck & x \\ \hline
	OuterTypeFilenameCheck & x \\ \hline
	OverloadMethodsDeclarationOrderCheck & x \\ \hline
	PackageDeclarationCheck & x \\ \hline
	ParameterAssignmentCheck & x \\ \hline
	RedundantModifierCheck & x \\ \hline
	RegexpMultilineCheck & x \\ \hline
	StaticVariableNameCheck & x \\ \hline
	SummaryJavadocCheck & x \\ \hline
	TrailingCommentCheck & x \\ \hline
	UpperEllCheck & x \\ \hline
	VariableDeclarationUsageDistanceCheck & x \\ \hline
	VisibilityModifierCheck & x \\ \hline
	WhitespaceAroundCheck & x \\ \hline
	WriteTagCheck & x \\ \hline
	sonarscanner:test\_success\_density & x \\ \hline
	sonarscanner:uncovered\_lines & x \\ \hline
	sonarscanner:cognitive\_complexity & x \\ \hline
	sonarscanner:coverage & x \\ \hline
	sonarscanner:line\_coverage & x \\ \hline
	sonarscanner:sqale\_rating & x \\ \hline
	sonarscanner:vulnerabilities & x \\ \hline
	sonarscanner:public\_undocumented\_api & x \\ \hline
	sonarscanner:effort\_to\_reach\_maintainability\_rating\_a & x \\ \hline
	sonarscanner:duplicated\_lines\_density & x \\ \hline
	sonarscanner:code\_smells & x \\ \hline
	sonarscanner:bugs & x \\ \hline
	sonarscanner:reliability\_rating & x \\ \hline
	sonarscanner:violations & x \\ \hline
	sonarscanner:lines\_to\_cover & x \\ \hline
	\caption{Metrikmatrix mit der Gewichtung der einzelnen Metriken}
\end{longtable}

Anhand der in Tabelle \ref{metric_matrix} dargestellten Gewichtsverteilung über die Metriken wird nach der Analyse die Anzahl an Punkten berechnet, die der Autor des Commits bekommt.
Auf Basis der erhaltenen Punkte wird dann das aktuelle Level des Autors bei Bedarf angepasst.

\section{Gamification-Elemente}
\label{Gamification_Elemente}
Um den Punkte- und Levelstand der einzelnen Autoren aber auch der jeweiligen Projektteams darzustellen, werden verschiedene Gamification-Elemente verwendet.
Im folgenden werden auf Basis der bisherigen Benutzerschnittstelle Prototypen für die Erweiterungen erstellt.
Bei der Konzeptionierung der Prototypen wird besonders auf die beabsichtigte Wirkung der jeweiligen Gamification-Elemente eingegangen.

Die in diesem Abschnitt aufgeführten Quests, Badges und Zusatzfunktionen sind jeweils Beispiele.
Die Programmierung muss hier so gestaltet werden, dass Ergänzungen ohne großen Aufwand vorgenommen werden können.

Zusätzlich muss im Rahmen der auf diese Arbeit folgenden Masterarbeit noch eine Balancierung der Punkte erarbeitet werden.
Diese Balancierung soll dafür sorgen, dass die erhaltenen Punkte in einem angemessenen Verhältnis zu den für die einzelnen Level benötigten Punkten stehen.
Ebenso soll die Balancierung eine angemessene Verteilung von Coins ermöglichen.
Diese Balancierung wird nicht im Rahmen dieser Arbeit vorgenommen, da der Fokus in dieser Arbeit lediglich auf der Implementierung der Gamification-Elemente in coderadar liegt.
Die Balancierung muss auf den durchzuführenden Feldversuch angepasst werden, damit die Nutzer innerhalb des Versuchszeitraums einen angemessenen Fortschritt erreichen können, es aber auch genug \glqq Spielinhalt\grqq{} für den Feldversuch gibt.

\subsection{Punkte}
\label{coderadar_Punkte}
Ein Autor erhält wie bereits erwähnt für das Einreichen eines Commits Punkte.
Dadurch ist es möglich, positive Handlungen beziehungsweise qualitativ hochwertigen Code direkt mit vielen Punkten zu belohnen und qualitativ schlechten Code mit wenig oder keinen Punkten zu bestrafen.
Die Anzahl an Punkten ermöglicht überdies einen einfachen Vergleich zwischen verschiedenen Autoren oder zwischen verschiedenen Zeitpunkten der Betrachtung des Profils eines Autors.
Die Punkte dienen somit auch als Basis für einige der anderen Gamification-Elemente, auf die im Laufe dieses Abschnitts eingegangen wird.
Der Nutzer bekommt seinen aktuellen Punktestand in Form eines Fortschrittsbalken zum nächsten Level angezeigt.
Dieser Fortschrittsbalken wird in der Benutzerschnittstelle wie in Abbildung \ref{mock_level} am unteren Bildschirmrand angezeigt.

\subsection{Level}
\label{coderadar_Level}
Level dienen als zusätzliche Motivation für den Nutzer, möglichst viele Punkte zu erhalten.
So können mit höherem Level bestimmte optische Zusatzfunktionen freigeschaltet werden.
Der Fortschritt im aktuellen Level wird in den Ansichten, in denen der verfügbare Platz dies zulässt, beispielsweise nicht in der City-View oder der Dependency-Map, an prominenter Stelle mittels eines Fortschrittsbalkens dargestellt.
An dieser Stelle sind folgende Funktionen mit dem entsprechend benötigten Level geplant.

\begin{center}
	\begin{tabular}{|p{12cm}|p{1cm}|}
		\hline
		Zusatzfunktion & Level \\ \hline
		Einen Titel zum Anzeigenamen hinzufügen & x \\ \hline
		Der Fortschrittsbalken für das Level kann alternativ auch den Fortschritt auf ein anderes Ziel hin darstellen & x \\ \hline
		Das Farbschema der Benutzeroberfläche kann angepasst werden & x \\ \hline
		Die Auswahl an Badges, die anderen Nutzern angezeigt werden, kann personalisiert werden & x \\ \hline
	\end{tabular}
\end{center}

Das Level wird in der Benutzeroberfläche neben dem Nutzernamen angezeigt und ist somit jederzeit präsent.
Abbildung \ref{mock_level} zeigt die Startseite der coderadar-Benutzeroberfläche.
Oben rechts neben dem Anzeigenamen des Nutzers wird das Level angezeigt.
Am unteren Bildschirmrand ist der Fortschrittsbalken, der den Punktestand im aktuellen Level darstellt.

\subsection{Badges}
\label{coderadar_Badges}
Badges werden innerhalb von coderadar als Statussymbol genutzt.
Sie zeigen an, dass der Inhaber des jeweiligen Badge eine bestimmte Leistung erbracht hat, die mit dem Badge gewürdigt wurde.
Nachfolgend sind die zu implementierenden Badges aufgelistet.
Einige der Badges haben dabei mehrere Abstufungen, die visuell durch eine unterschiedliche Farbgebung in bronze, silber und gold repräsentiert werden.

\begin{center}
	\begin{tabular}{|c|c|c|c|c|}
		\hline
		Titel & Beschreibung & Ziel & Ziel 2 & Ziel 3 \\ \hline
		Bug hunter & Bestimmte Anzahl an Bugs gefixt & 10 & 25 & 100 \\ \hline
		Security & Vulnerabilities gefixt & 10 & 25 & 100 \\ \hline
		Test-Experte & Anzahl an Zeilen, die von Tests gedeckt sind & 1000 & 2500 & 10000 \\ \hline
		Code maniac & Zeilen Code geschrieben & 10000 & 25000 & 100000 \\ \hline
		Clean coder & Zeilen Code ohne Verletzung von Stilrichtlinien & 1000 & 2500 & 10000 \\ \hline
		holistic & TODOs gefixt & 2 & 5 & 10 \\ \hline
		commentator & Public API Kommentare hinzugefügt & 10 & 25 & 100 \\ \hline
		Quest solver & Quests abgeschlossen & 2 & 5 & 10 \\ \hline
		Maniac & Maximallevel erreicht & 1 & - & - \\ \hline
		x & Werktage in folge eingeloggt & 5 & 15 & 40 \\ \hline
	\end{tabular}
\end{center}

Abbildung \ref{mock_badge_list} zeigt eine Seite, in der der Nutzer sehen kann, welche Badges es gibt und wie sein Fortschritt bei den Badges ist, die er noch nicht erreicht hat.
Hat der Nutzer das entsprechende Level erreicht, kann er in dieser Ansicht auch auswählen, welche Badges anderen Nutzern angezeigt werden sollen.
Dies geschieht über die Checkbox neben dem jeweiligen Badge.
Hat der Nutzer das erforderliche Level noch nicht erreicht, ist diese Checkbox deaktiviert.

Abbildung \ref{mock_leaderboards_global} zeigt, wie die Badges anderen Nutzern in den Bestenlisten angezeigt werden.

\subsection{Bestenlisten}
\label{coderadar_Bestenlisten}
Die nutzerbezogenen Bestenlisten in coderadar zeigen gemäß Anforderung F.5 neben dem Nutzernamen auch die erreichten Badges und den Titel des Nutzers.
Zum einen gibt es eine globale Bestenliste über alle Nutzer.
Der Nutzer sieht hier sowohl die 10 besten, als auch die 10 Nutzer um ihn herum.
Der Prototyp dieser Ansicht ist in Abbildung \ref{mock_leaderboards_global} dargestellt.

Zusätzlich gibt es gemäß Anforderung F.4 eine projektbezogene Bestenliste, die die Summe der Leistungen der einzelnen Contributors des jeweiligen Projekts anzeigt.
Abbildung \ref{mock_leaderboards_projects} zeigt eine solche projektbezogene Bestenliste.
Die Bestenliste geht dabei nicht auf die einzelnen Contributors ein sondern zeigt das Teamergebnis.
Für Nutzer, die nicht dem Projektteam angehören, ist es so nicht möglich, Rückschlüsse auf die Leistungen der einzelnen Nutzer zu ziehen.

\subsection{Avatar- und Profilentwicklung}
\label{coderadar_Profil}
Der Nutzer hat in coderadar die Möglichkeit, sich sein Profil anzeigen zu lassen.
In dieser Darstellung werden dem Nutzer sein aktueller Level- und Punktestand angezeigt (vgl. Abbildung \ref{mock_profile}).
Darüber hinaus werden die vom Nutzer abgeschlossenen Quest und die erhaltenen Badges dargestellt.
Außerdem kann sich der Nutzer seine Coins anzeigen und auszahlen lassen.

\subsection{Coins}
\label{coderadar_Coins}
Der Nutzer erhält für das Lösen von Quests und das erreichen bestimmter Level Coins.
Die Coins sollen später in reale Belohnungen umgetauscht werden können.
In wie weit dies möglich ist muss aber noch im Rahmen der an diese Arbeit folgenden Masterarbeit geklärt werden.
Im Rahmen des noch durchzuführenden Feldversuchs wäre hier beispielsweise eine Integration mit dem adesso Shop oder ein Amazon-Gutschein denkbar.

\subsection{Quests}
\label{coderadar_Quests}
Für den Feldversuch sollen verschiedene Quests zur Verfügung stehen.
Für das Lösen einer Quest wird der Nutzer mit Punkten und Coins belohnt.
Nachfolgend sind die geplanten Quests mit den Titeln, Beschreibungen und Belohnungen aufgelistet.
Die hier aufgeführte Beschreibung ist sehr kurz gehalten und muss in der eigentlichen Implementierung noch erweitert werden.

\begin{center}
	\begin{tabular}{|c|c|c|c|c|}
		\hline
		Titel & Beschreibung & Punkte & Coins & Ab Level \\ \hline
		
	\end{tabular}
\end{center}

Die Quests werden dabei ab einem bestimmten Level freigeschaltet. 
Sobald der Nutzer das benötigte Level erreicht hat, wird die Quest in der Liste der verfügbaren Quests angezeigt (vgl. Abbildung \ref{mock_quest_overview}).
Die genaueren Informationen zu den jeweiligen Quests können auf einer Detailseite angezeigt werden (vgl. Abbildung \ref{mock_quest}).

\chapter{Umsetzung}
\label{Umsetzung}


\section{Programmierung}
\label{Programmierung}


\chapter{Abschluss}
\label{Abschluss}


\section{Verifizierung der Anforderungen}
\label{Verifizierung_Anforderungen}


\section{Fazit}
\label{Fazit}


\addchap{Anhang} 
\refstepcounter{chapter} 
\begin{figure}[htb]
	\begin{center}
		\includegraphics[width=\linewidth]{images/city_view}
		\caption{Ein Beispiel für die City-View.}
		\label{city_view}
	\end{center}
\end{figure}

\begin{figure}[htb]
	\begin{center}
		\includegraphics[width=\linewidth]{images/dependency_map}
		\caption{Ein Beispiel für die Dependency-Map.}
		\label{dependency_map}
	\end{center}
\end{figure}

\begin{figure}[htb]
	\begin{center}
		\includegraphics[width=\linewidth]{images/tree_view}
		\caption{Die Baumansicht der Commits in coderadar.}
		\label{tree_view}
	\end{center}
\end{figure}

\begin{figure}[htb]
	\begin{center}
		\includegraphics[width=\linewidth]{images/mock_level}
		\caption{Der Prototyp der Darstellung des Level des Nutzers.}
		\label{mock_level}
	\end{center}
\end{figure}

\begin{figure}[htb]
	\begin{center}
		\includegraphics[width=\linewidth]{images/mock_badge_list}
		\caption{Der Prototyp der Übersicht über die Badges.}
		\label{mock_badge_list}
	\end{center}
\end{figure}

\begin{figure}[htb]
	\begin{center}
		\includegraphics[width=\linewidth]{images/mock_leaderboards_global}
		\caption{Der Prototyp der Bestenliste über alle Nutzer.}
		\label{mock_leaderboards_global}
	\end{center}
\end{figure}

\begin{figure}[htb]
	\begin{center}
		\includegraphics[width=\linewidth]{images/mock_leaderboards_projects}
		\caption{Der Prototyp der Bestenliste über alle Projekte.}
		\label{mock_leaderboards_projects}
	\end{center}
\end{figure}

\begin{figure}[htb]
	\begin{center}
		\includegraphics[width=\linewidth]{images/mock_profile}
		\caption{Der Prototyp der Darstellung des Profils des Nutzers.}
		\label{mock_profile}
	\end{center}
\end{figure}

\begin{figure}[htb]
	\begin{center}
		\includegraphics[width=\linewidth]{images/mock_quest_list}
		\caption{Der Prototyp der Darstellung der Übersicht über die Quests.}
		\label{mock_quest_overview}
	\end{center}
\end{figure}

\begin{figure}[htb]
	\begin{center}
		\includegraphics[width=\linewidth]{images/mock_quest}
		\caption{Der Prototyp der Darstellung einer Quest.}
		\label{mock_quest}
	\end{center}
\end{figure}

%___________________________________________________________________________________________________

% Abkürzungsverzeichnis ins Inhaltsverzeichnis aufnehmen und mit Inhalt füllen
\cleardoublepage\phantomsection\addcontentsline{toc}{chapter}{Abkürzungsverzeichnis}
\chapter*{Abkürzungsverzeichnis}
\begin{acronym}
	\acro{ISO}{International Organization for Standardization} % 227
	\acro{REST}{Representational State Transfer} % 453
	\acro{SOAP}{Simple Object Access Protocol} % 453
	\acro{OWASP}{Open Web Application Security Project} % 494
	\acro{CWE}{Common Weakness Enumeration} % 587
	\acro{LOC}{Lines of Code} % 712
	\acro{CLI}{Command Line Interface} % 955		
	\acro{JRE}{Java Runtime Environment} % 976
\end{acronym}

\newpage{}

% Weitere Verzeichnisse ins Inhaltsverzeichnis aufnehmen
\cleardoublepage\phantomsection\addcontentsline{toc}{chapter}{Abbildungsverzeichnis}
\listoffigures

\newpage{}

\cleardoublepage\phantomsection\addcontentsline{toc}{chapter}{Tabellenverzeichnis}
\listoftables

\lstlistoflistings 
	
% Literaturverzeichnis setzen
\bibliographystyle{alphadin}
\bibliography{bib}
	
% Eidesstattliche Erklärung. ACHTUNG: Korrekten Text bitte unbedingt vorab mit Studienbüro klären!
\chapter*{Eidesstattliche Erklärung}
\thispagestyle{empty}
\textbf{ACHTUNG: Korrekten Text bitte unbedingt vorab mit Studienbüro klären!}\\
Hiermit versichere ich gemäß § 18 Abs. 5 der Bachelor-Prüfungsordnung des Studiengangs Informatik aus dem Jahr 2013, dass ich die  vorliegende Arbeit selbstständig angefertigt und mich keiner fremden Hilfe bedient, sowie keine anderen als die angegebenen Quellen und Hilfsmittel benutzt habe. Alle Stellen, die wörtlich oder sinngemäß veröffentlichten oder nicht veröffentlichten Schriften und anderen Quellen entnommen sind, habe ich als solche kenntlich gemacht. Diese Arbeit hat in gleicher oder ähnlicher Form noch keiner Prüfungsbehörde vorgelegen.

\vspace{1\baselineskip}%
Dortmund, \fhdopaperdate \hfill \fhdopaperauthor
\end{document}